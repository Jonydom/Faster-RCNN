{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2534fe3",
   "metadata": {},
   "source": [
    "# 1）将coco2017数据集进行切分，生成minicoco2017数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8796ac21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=19.73s)\n",
      "creating index...\n",
      "index created!\n",
      "100% [............................................................................] 236406 / 236406\n",
      "finish.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pycocotools.coco import COCO\n",
    "import wget\n",
    "import numpy as np\n",
    "from random import sample\n",
    "from pathlib import Path\n",
    "from joblib import delayed, Parallel\n",
    "\n",
    "ANNOTATIONS = {\"info\": {\n",
    "    \"description\": \"minicoco2017\"\n",
    "}\n",
    "}\n",
    "\n",
    "def myImages(images: list, train: int, val: int) -> tuple:\n",
    "    myImagesTrain = images[:train]\n",
    "    myImagesVal = images[train:train+val]\n",
    "    return myImagesTrain, myImagesVal\n",
    "\n",
    "\n",
    "def cocoJson(images: list) -> dict:\n",
    "    arrayIds = np.array([k[\"id\"] for k in images])\n",
    "    annIds = coco.getAnnIds(imgIds=arrayIds, catIds=catIds, iscrowd=None)\n",
    "    anns = coco.loadAnns(annIds)\n",
    "    for k in anns:\n",
    "        k[\"category_id\"] = catIds.index(k[\"category_id\"])+1\n",
    "    catS = [{'id': int(value), 'name': key}\n",
    "            for key, value in categories.items()]\n",
    "    ANNOTATIONS[\"images\"] = images\n",
    "    ANNOTATIONS[\"annotations\"] = anns\n",
    "    ANNOTATIONS[\"categories\"] = catS\n",
    "\n",
    "    return ANNOTATIONS\n",
    "\n",
    "\n",
    "def createJson(JsonFile: json, train: bool) -> None:\n",
    "    name = \"train\"\n",
    "    if not train:\n",
    "        name = \"val\"\n",
    "    Path(\"minicoco2017/annotations\").mkdir(parents=True, exist_ok=True)\n",
    "    with open(f\"minicoco2017/annotations/{name}2017.json\", \"w\") as outfile:\n",
    "        json.dump(JsonFile, outfile)\n",
    "\n",
    "\n",
    "def downloadImagesToTrain(img: dict) -> None:\n",
    "    link = (img['coco_url'])\n",
    "    Path(\"minicoco2017/train2017\").mkdir(parents=True, exist_ok=True)\n",
    "    wget.download(link, f\"{'minicoco2017/train2017/' + img['file_name']}\")\n",
    "\n",
    "def downloadImagesToVal(img: dict) -> None:\n",
    "    link = (img['coco_url'])\n",
    "    Path(\"minicoco2017/val2017\").mkdir(parents=True, exist_ok=True)\n",
    "    wget.download(link, f\"{'minicoco2017/val2017/' + img['file_name']}\")\n",
    "\n",
    "coco = COCO('./coco2017/annotations/instances_train2017.json')\n",
    "\n",
    "catNms = ['car', 'airplane', 'person']\n",
    "\n",
    "catIds = coco.getCatIds(catNms) \n",
    "\n",
    "dictCOCO = {k: coco.getCatIds(k)[0] for k in catNms}  \n",
    "dictCOCOSorted = dict(sorted(dictCOCO.items(), key=lambda x: x[1]))  \n",
    "\n",
    "IdCategories = list(range(1, len(catNms)+1)) \n",
    "categories = dict(zip(list(dictCOCOSorted), IdCategories)) \n",
    "\n",
    "# Get the corresponding image ids and images using loadImgs\n",
    "imgIds = coco.getImgIds(catIds=catIds) \n",
    "imgOriginals = coco.loadImgs(imgIds) \n",
    "\n",
    "# The images are selected randomly\n",
    "imgShuffled = sample(imgOriginals, len(imgOriginals))  \n",
    "\n",
    "# Choose the number of images for the training and validation set. default 30-10\n",
    "myImagesTrain, myImagesVal = myImages(imgShuffled, 30, 10)  \n",
    "\n",
    "trainSet = cocoJson(myImagesTrain)\n",
    "createJson(trainSet, train=True)\n",
    "\n",
    "valSet = cocoJson(myImagesVal)\n",
    "createJson(valSet, train=False)\n",
    "\n",
    "Parallel(\n",
    "    n_jobs=-1, prefer=\"threads\")([delayed(downloadImagesToTrain)(img) for img in myImagesTrain])\n",
    "\n",
    "Parallel(\n",
    "    n_jobs=-1, prefer=\"threads\")([delayed(downloadImagesToVal)(img) for img in myImagesVal])\n",
    "\n",
    "print(\"\\nfinish.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d22510",
   "metadata": {},
   "source": [
    "# 2）将minicoco2017数据集转换为mindrecord数据集\n",
    "1. 在根目录`./`中创建`MindRecord_COCO_TRAIN`文件夹，用于存储mindrecord数据文件和索引文件`FasterRcnn.mindrecord`、`FasterRcnn.mindrecord.db`；\n",
    "\n",
    "2. 将minicoco2017数据集的图片和标签，根据算法转换为存储mindrecord文件所需的格式，以训练数据集为例，具体实现流程如下：\n",
    "\n",
    "    a. 获取训练集数据中所有的类别标签，生成标签数组`train_cls=['background','person','car','airplane']`，对数组中每个标签从0开始编号，得到标签字典`train_cls_dict={'background':0,'person':1,'car':2,'airplane':3}`\n",
    "    \n",
    "    b. 使用pycocotools.coco工具访问minicoco2017数据集标签json文件`./minicoco2017/annotations/train2017.json`生成COCO类，使用COCO类获取标签json文件中所有类别的`id`和`name`信息，将这些信息存入字典中`classes_dict={'person':1,'car':2,'airplane':3}`；\n",
    "    \n",
    "    c. 使用COCO类获取获取所有标记所对应的原图id，并返回数组`image_ids=[50881,106430...]`；\n",
    "    \n",
    "    d. 遍历`image_ids`数组，根据每个图片的id找到其图片中所对应的所有物体标注id，根据标注id获得具体标注信息: 图片名称`filename`、 标记框坐标信息`（x,y,w,h,iscrowd）`；根据`x, y, w, h`计算标注框的左上角和右下角的位置坐标`(x1, y1), (x2, y2)`。在每次遍历时，将`filename`补全为相对路径，将路径字符串存入`image_files`数组；将图片相对路径作为key，标记框信息作为value，生成字典`image_anno_dict`；\n",
    "    \n",
    "    e. 使用mindspore.mindrecord中的写文件函数`FileWriter`，遍历字典`image_anno_dict`，根据图片文件路径读取文件的二进制信息，将每一个标记框信息写入mindrecord文件中`FasterRcnn.mindrecord`，每一个行的数据格式为`{'image':图片二进制信息, 'annotation':标记框信息}`。\n",
    "\n",
    "3. 根据mindrecord文件`FasterRcnn.mindrecord`生成dataset\n",
    "使用自定义Python函数进行数据增强，数据增强时采用多进程优化方案，开启了4个进程并发完成任务。\n",
    "\n",
    "代码优化：将np.bool更改为bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "087a8a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"FasterRcnn dataset\"\"\"\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "\n",
    "import cv2\n",
    "import mindspore as ms\n",
    "import mindspore.dataset as de\n",
    "from mindspore.mindrecord import FileWriter\n",
    "from src.image_process import *\n",
    "\n",
    "\n",
    "def preprocess_fn(image, box, is_training, config):\n",
    "    \"\"\"Preprocess function for dataset.\"\"\"\n",
    "\n",
    "    def _infer_data(image_bgr, image_shape, gt_box_new, gt_label_new, gt_iscrowd_new_revert):\n",
    "        image_shape = image_shape[:2]\n",
    "        input_data = image_bgr, image_shape, gt_box_new, gt_label_new, gt_iscrowd_new_revert\n",
    "\n",
    "        if config.keep_ratio:\n",
    "            input_data = rescale_column_test(*input_data, config=config)\n",
    "        else:\n",
    "            input_data = resize_column_test(*input_data, config=config)\n",
    "        input_data = imnormalize_column(*input_data)\n",
    "\n",
    "        output_data = transpose_column(*input_data)\n",
    "        return output_data\n",
    "\n",
    "    def _data_aug(image, box, is_training):\n",
    "        \"\"\"Data augmentation function.\"\"\"\n",
    "        pad_max_number = config.num_gts\n",
    "        if pad_max_number < box.shape[0]:\n",
    "            box = box[:pad_max_number, :]\n",
    "        image_bgr = image.copy()\n",
    "        image_bgr[:, :, 0] = image[:, :, 2]\n",
    "        image_bgr[:, :, 1] = image[:, :, 1]\n",
    "        image_bgr[:, :, 2] = image[:, :, 0]\n",
    "        image_shape = image_bgr.shape[:2]\n",
    "        gt_box = box[:, :4]\n",
    "        gt_label = box[:, 4]\n",
    "        gt_iscrowd = box[:, 5]\n",
    "\n",
    "        gt_box_new = np.pad(gt_box, ((0, pad_max_number - box.shape[0]), (0, 0)), mode=\"constant\", constant_values=0)\n",
    "        gt_label_new = np.pad(gt_label, ((0, pad_max_number - box.shape[0])), mode=\"constant\", constant_values=-1)\n",
    "        gt_iscrowd_new = np.pad(gt_iscrowd, ((0, pad_max_number - box.shape[0])), mode=\"constant\", constant_values=1)\n",
    "        gt_iscrowd_new_revert = (~(gt_iscrowd_new.astype(np.bool))).astype(np.int32)\n",
    "\n",
    "        if not is_training:\n",
    "            return _infer_data(image_bgr, image_shape, gt_box_new, gt_label_new, gt_iscrowd_new_revert)\n",
    "\n",
    "        flip = (np.random.rand() < config.flip_ratio)\n",
    "        expand = (np.random.rand() < config.expand_ratio)\n",
    "        input_data = image_bgr, image_shape, gt_box_new, gt_label_new, gt_iscrowd_new_revert\n",
    "\n",
    "        if expand:\n",
    "            input_data = expand_column(*input_data)\n",
    "        if config.keep_ratio:\n",
    "            input_data = rescale_column(*input_data, config=config)\n",
    "        else:\n",
    "            input_data = resize_column(*input_data, config=config)\n",
    "        input_data = imnormalize_column(*input_data)\n",
    "        if flip:\n",
    "            input_data = flip_column(*input_data)\n",
    "\n",
    "        output_data = transpose_column(*input_data)\n",
    "        return output_data\n",
    "\n",
    "    return _data_aug(image, box, is_training)\n",
    "\n",
    "\n",
    "def create_coco_label(is_training, config):\n",
    "    \"\"\"Get image path and annotation from COCO.\"\"\"\n",
    "    from pycocotools.coco import COCO\n",
    "\n",
    "    coco_root = config.coco_root  # coco_root: \"./minicoco2017\"\n",
    "    data_type = config.val_data_type\n",
    "    if is_training:\n",
    "        data_type = config.train_data_type  # train_data_type: \"train2017\"\n",
    "\n",
    "    # Classes need to train or test.\n",
    "    train_cls = config.coco_classes  # coco_classes: ['person','car', 'airplane']\n",
    "    train_cls_dict = {}\n",
    "    for i, cls in enumerate(train_cls):\n",
    "        train_cls_dict[cls] = i  # train_cls_dict: {'person': 0, 'airplane': 1, 'car': 2}\n",
    "\n",
    "    anno_json = os.path.join('.', coco_root, config.instance_set.format(data_type))  # anno_json: \"../minicoco2017/annotations/train2017.json\"\n",
    "    if hasattr(config, 'train_set') and is_training:\n",
    "        anno_json = os.path.join(coco_root, config.train_set)\n",
    "    if hasattr(config, 'val_set') and not is_training:\n",
    "        anno_json = os.path.join(coco_root, config.val_set)\n",
    "\n",
    "    # 根据annotations json文件创建COCO类\n",
    "    coco = COCO(anno_json)\n",
    "    classs_dict = {}\n",
    "    cat_ids = coco.loadCats(coco.getCatIds()) # 获取所有的类别信息，loadCats()需要传入 需加载的类别id序列\n",
    "    for cat in cat_ids:\n",
    "        classs_dict[cat[\"id\"]] = cat[\"name\"] # classes_dict: {1:'person', 2:'car'...}\n",
    "\n",
    "    image_ids = coco.getImgIds() # 获取所有 标记所对应的原图id  image_ids: [391895, 522418...]\n",
    "    # 创建要返回的变量\n",
    "    image_files = []\n",
    "    image_anno_dict = {}\n",
    "\n",
    "    for img_id in image_ids:\n",
    "        image_info = coco.loadImgs(img_id)\n",
    "        file_name = image_info[0][\"file_name\"]\n",
    "        anno_ids = coco.getAnnIds(imgIds=img_id, iscrowd=None)\n",
    "        anno = coco.loadAnns(anno_ids)\n",
    "        image_path = os.path.join(coco_root, data_type, file_name)\n",
    "        annos = []\n",
    "        for label in anno:\n",
    "            bbox = label[\"bbox\"]\n",
    "            class_name = classs_dict[label[\"category_id\"]]\n",
    "            if class_name in train_cls:\n",
    "                x1, x2 = bbox[0], bbox[0] + bbox[2]\n",
    "                y1, y2 = bbox[1], bbox[1] + bbox[3]\n",
    "                annos.append([x1, y1, x2, y2] + [train_cls_dict[class_name]] + [int(label[\"iscrowd\"])])\n",
    "\n",
    "        image_files.append(image_path)\n",
    "        if annos:\n",
    "            image_anno_dict[image_path] = np.array(annos)\n",
    "        else:\n",
    "            image_anno_dict[image_path] = np.array([0, 0, 0, 0, 0, 1])\n",
    "\n",
    "    return image_files, image_anno_dict\n",
    "\n",
    "# 可能用于评估\n",
    "def parse_json_annos_from_txt(anno_file, config):\n",
    "    \"\"\"for user defined annotations text file, parse it to json format data\"\"\"\n",
    "    if not os.path.isfile(anno_file):\n",
    "        raise RuntimeError(\"Evaluation annotation file {} is not valid.\".format(anno_file))\n",
    "\n",
    "    annos = {\n",
    "        \"images\": [],\n",
    "        \"annotations\": [],\n",
    "        \"categories\": []\n",
    "    }\n",
    "\n",
    "    # set categories field\n",
    "    for i, cls_name in enumerate(config.coco_classes):\n",
    "        annos[\"categories\"].append({\"id\": i, \"name\": cls_name})\n",
    "\n",
    "    with open(anno_file, \"rb\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    img_id = 1\n",
    "    anno_id = 1\n",
    "    for line in lines:\n",
    "        line_str = line.decode(\"utf-8\").strip()\n",
    "        line_split = str(line_str).split(' ')\n",
    "        # set image field\n",
    "        file_name = line_split[0]\n",
    "        annos[\"images\"].append({\"file_name\": file_name, \"id\": img_id})\n",
    "        # set annotations field\n",
    "        for anno_info in line_split[1:]:\n",
    "            anno = anno_info.split(\",\")\n",
    "            x = float(anno[0])\n",
    "            y = float(anno[1])\n",
    "            w = float(anno[2]) - float(anno[0])\n",
    "            h = float(anno[3]) - float(anno[1])\n",
    "            category_id = int(anno[4])\n",
    "            iscrowd = int(anno[5])\n",
    "            annos[\"annotations\"].append({\"bbox\": [x, y, w, h],\n",
    "                                         \"area\": w * h,\n",
    "                                         \"category_id\": category_id,\n",
    "                                         \"iscrowd\": iscrowd,\n",
    "                                         \"image_id\": img_id,\n",
    "                                         \"id\": anno_id})\n",
    "            anno_id += 1\n",
    "        img_id += 1\n",
    "\n",
    "    return annos\n",
    "\n",
    "\n",
    "def create_train_data_from_txt(image_dir, anno_path):\n",
    "    \"\"\"Filter valid image file, which both in image_dir and anno_path.\"\"\"\n",
    "\n",
    "    def anno_parser(annos_str):\n",
    "        \"\"\"Parse annotation from string to list.\"\"\"\n",
    "        annos = []\n",
    "        for anno_str in annos_str:\n",
    "            anno = anno_str.strip().split(\",\")\n",
    "            xmin, ymin, xmax, ymax = list(map(float, anno[:4]))\n",
    "            cls_id = int(anno[4])\n",
    "            iscrowd = int(anno[5])\n",
    "            annos.append([xmin, ymin, xmax, ymax, cls_id, iscrowd])\n",
    "        return annos\n",
    "\n",
    "    image_files = []\n",
    "    image_anno_dict = {}\n",
    "    if not os.path.isdir(image_dir):\n",
    "        raise RuntimeError(\"Path given is not valid.\")\n",
    "    if not os.path.isfile(anno_path):\n",
    "        raise RuntimeError(\"Annotation file is not valid.\")\n",
    "\n",
    "    with open(anno_path, \"rb\") as f:\n",
    "        lines = f.readlines()\n",
    "    for line in lines:\n",
    "        line_str = line.decode(\"utf-8\").strip()\n",
    "        line_split = str(line_str).split(' ')\n",
    "        file_name = line_split[0]\n",
    "        image_path = os.path.join(image_dir, file_name)\n",
    "        if os.path.isfile(image_path):\n",
    "            image_anno_dict[image_path] = anno_parser(line_split[1:])\n",
    "            image_files.append(image_path)\n",
    "    return image_files, image_anno_dict\n",
    "\n",
    "\n",
    "def data_to_mindrecord_byte_image(config, dataset=\"coco\", is_training=True, prefix=\"fasterrcnn.mindrecord\", file_num=1):\n",
    "    \"\"\"Create MindRecord file.\"\"\"\n",
    "    mindrecord_dir = config.mindrecord_dir  # mindrecord_dir: \"./MindRecord_COCO_TRAIN\"\n",
    "    mindrecord_path = os.path.join(mindrecord_dir, prefix)  # mindrecord_file: \"/MindRecord_COCO_TRAIN/FasterRcnn.mindrecord0\"\n",
    "    writer = FileWriter(mindrecord_path, file_num)\n",
    "    if dataset == \"coco\":\n",
    "        image_files, image_anno_dict = create_coco_label(is_training, config=config)\n",
    "    else:\n",
    "        image_files, image_anno_dict = create_train_data_from_txt(config.image_dir, config.anno_path)\n",
    "\n",
    "    fasterrcnn_json = {\n",
    "        \"image\": {\"type\": \"bytes\"},\n",
    "        \"annotation\": {\"type\": \"int32\", \"shape\": [-1, 6]},\n",
    "    }\n",
    "    writer.add_schema(fasterrcnn_json, \"fasterrcnn_json\")\n",
    "\n",
    "    for image_name in image_files:\n",
    "        with open(image_name, 'rb') as f:\n",
    "            img = f.read()\n",
    "        annos = np.array(image_anno_dict[image_name], dtype=np.int32)\n",
    "        row = {\"image\": img, \"annotation\": annos}\n",
    "        writer.write_raw_data([row])\n",
    "    writer.commit()\n",
    "\n",
    "\n",
    "def create_fasterrcnn_dataset(config, mindrecord_file, batch_size=2, device_num=1, rank_id=0, is_training=True,\n",
    "                              num_parallel_workers=8, python_multiprocessing=False):\n",
    "    \"\"\"Create FasterRcnn dataset with MindDataset.\"\"\"\n",
    "    cv2.setNumThreads(0)\n",
    "    de.config.set_prefetch_size(1)\n",
    "    ds = de.MindDataset(mindrecord_file, columns_list=[\"image\", \"annotation\"], num_shards=device_num, shard_id=rank_id,\n",
    "                        num_parallel_workers=4, shuffle=is_training)\n",
    "    decode = ms.dataset.vision.Decode()\n",
    "    ds = ds.map(input_columns=[\"image\"], operations=decode)\n",
    "    compose_map_func = (lambda image, annotation: preprocess_fn(image, annotation, is_training, config=config))\n",
    "\n",
    "    if is_training:\n",
    "        ds = ds.map(input_columns=[\"image\", \"annotation\"],\n",
    "                    output_columns=[\"image\", \"image_shape\", \"box\", \"label\", \"valid_num\"],\n",
    "                    column_order=[\"image\", \"image_shape\", \"box\", \"label\", \"valid_num\"],\n",
    "                    operations=compose_map_func, python_multiprocessing=python_multiprocessing,\n",
    "                    num_parallel_workers=num_parallel_workers)\n",
    "        ds = ds.batch(batch_size, drop_remainder=True)\n",
    "    else:\n",
    "        ds = ds.map(input_columns=[\"image\", \"annotation\"],\n",
    "                    output_columns=[\"image\", \"image_shape\", \"box\", \"label\", \"valid_num\"],\n",
    "                    column_order=[\"image\", \"image_shape\", \"box\", \"label\", \"valid_num\"],\n",
    "                    operations=compose_map_func,\n",
    "                    num_parallel_workers=num_parallel_workers)\n",
    "        ds = ds.batch(batch_size, drop_remainder=True)\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcad9864",
   "metadata": {},
   "source": [
    "# 生成anchor\n",
    "在Faster-RCNN网络的RPN阶段中，需要根据backbone网络抽取的feature map的大小，对每个点生成相应的anchor。所谓anchor，实际上就是一组矩形框，它们的大小、尺寸、位置坐标由base_size、scales、ratios和featmap_size决定。对于一个由ResNet50提取的特征图feature map，生成anchor的大致流程如下：\n",
    "1) 首先有个base_size，指定生成的基础anchor的大小，生成的基础anchor的长和宽都是base_size，这时候只有一个anchor；\n",
    "\n",
    "2) 以base_size的大小为基础，按照三种长宽比ratios{2:1, 1:1, 1:2}，生成指定长宽比的基础anchor；\n",
    "\n",
    "3) 根据指定的缩放比例，对基础anchor进行缩放，本案例中缩放比例一共有1种，缩放比例为8，三种长宽比和一种缩放比例，就得到了3 * 1 = 3个基础anchor；\n",
    "\n",
    "4) 上面的过程描述了特征上一个cell对应的anchor的生成过程，对于特征图上的每个cell，都要生成3个anchor。在本案例中，提供了一个stride参数，用于将在feature map上生成的anchor尺寸还原为原图中的anchor尺寸。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a59ceb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class AnchorGenerator():\n",
    "    def __init__(self, base_size, scales, ratios):\n",
    "        self.base_size = base_size\n",
    "        self.scales = np.array(scales)\n",
    "        self.ratios = np.array(ratios)\n",
    "        self.base_anchors = self.gen_base_anchors()\n",
    "    def gen_base_anchors(self):\n",
    "        # 生成feather map中一个点的anchors\n",
    "        w = self.base_size\n",
    "        h = self.base_size\n",
    "        x_ctr = 0.5 * (w - 1)\n",
    "        y_ctr = 0.5 * (h - 1)\n",
    "        h_ratios = np.sqrt(self.ratios)\n",
    "        w_ratios = 1 / h_ratios\n",
    "        ws = (w * w_ratios[:, None] * self.scales[None, :]).reshape(-1)\n",
    "        hs = (h * h_ratios[:, None] * self.scales[None, :]).reshape(-1)\n",
    "        base_anchors = np.stack([\n",
    "            x_ctr - 0.5 * (ws - 1), y_ctr - 0.5 * (hs - 1),\n",
    "            x_ctr + 0.5 * (ws - 1), y_ctr + 0.5 * (hs - 1)\n",
    "        ], axis=-1).round()\n",
    "        return base_anchors\n",
    "    def _meshgrid(self, x, y, row_major=True):\n",
    "        xx = np.repeat(x.reshape(1, len(x)), len(y), axis=0).reshape(-1)\n",
    "        yy = np.repeat(y, len(x))\n",
    "        if row_major:\n",
    "            return xx, yy\n",
    "        return yy, xx\n",
    "    def grid_anchors(self, featmap_size, stride=16):\n",
    "        # 根据feature map的大小，生成对应的所有anchors\n",
    "        base_anchors = self.base_anchors\n",
    "        \n",
    "        feat_h, feat_w = featmap_size\n",
    "        shift_x = np.arange(0, feat_w) * stride\n",
    "        shift_y = np.arange(0, feat_h) * stride\n",
    "        shift_xx, shift_yy = self._meshgrid(shift_x, shift_y)\n",
    "        shifts = np.stack([shift_xx, shift_yy, shift_xx, shift_yy], axis=-1)\n",
    "        shifts = shifts.astype(base_anchors.dtype)\n",
    "        all_anchors = base_anchors[None, :, :] + shifts[:, None, :]\n",
    "        all_anchors = all_anchors.reshape(-1, 4)\n",
    "        \n",
    "        return all_anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ba5a01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 192*320 feature map, the number of generated anchors is 184320.\n",
      "Generated anchors as follow:\n",
      "[[ -21.   -9.   24.   12.]\n",
      " [ -14.  -14.   17.   17.]\n",
      " [  -9.  -21.   12.   24.]\n",
      " ...\n",
      " [1255.  755. 1300.  776.]\n",
      " [1262.  750. 1293.  781.]\n",
      " [1267.  743. 1288.  788.]]\n"
     ]
    }
   ],
   "source": [
    "base_size = 4\n",
    "scales = [8]\n",
    "ratios = [0.5, 1.0, 2.0]\n",
    "featmap_size = [192, 320]\n",
    "stride = 4\n",
    "x = AnchorGenerator(base_size, scales, ratios)\n",
    "all_anchors = x.grid_anchors(featmap_size, stride)\n",
    "print(f\"For {featmap_size[0]}*{featmap_size[1]} feature map, the number of generated anchors is {len(all_anchors)}.\")\n",
    "print(f\"Generated anchors as follow:\")\n",
    "print(all_anchors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe1a542",
   "metadata": {},
   "source": [
    "# ResNet50 backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48e54c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mindspore.nn as nn\n",
    "from mindspore.common.tensor import Tensor\n",
    "import mindspore.ops as ops\n",
    "import mindspore as ms\n",
    "\n",
    "def _conv(in_channels, out_channels, kernel_size=3, stride=1, padding=0, pad_mode='pad'):\n",
    "    shape = (out_channels, in_channels, kernel_size, kernel_size)\n",
    "    weights = Tensor(np.full(shape, 0.01).astype(np.float32))\n",
    "    return nn.Conv2d(in_channels, out_channels,\n",
    "                    kernel_size=kernel_size, stride=stride, padding=padding,\n",
    "                    pad_mode=pad_mode, weight_init=weights, has_bias=False)\n",
    "def _BatchNorm2dInit(out_chls, momentum=0.1, affine=True, use_batch_statistics=True):\n",
    "    dtype = np.float32\n",
    "    gamma_init = Tensor(np.array(np.ones(out_chls)).astype(dtype))\n",
    "    beta_init = Tensor(np.array(np.ones(out_chls) * 0).astype(dtype))\n",
    "    moving_mean_init = Tensor(np.array(np.ones(out_chls) * 0).astype(dtype))\n",
    "    moving_var_init = Tensor(np.array(np.ones(out_chls)).astype(dtype))\n",
    "    return nn.BatchNorm2d(out_chls, momentum=momentum, affine=affine, gamma_init=gamma_init,\n",
    "                          beta_init=beta_init, moving_mean_init=moving_mean_init,\n",
    "                          moving_var_init=moving_var_init, use_batch_statistics=use_batch_statistics)\n",
    "class ResNetFea(nn.Cell):\n",
    "    def __init__(self, block, layer_nums, in_channels, out_channels, weights_update=False):\n",
    "        super(ResNetFea, self).__init__()\n",
    "        bn_training = False  # 训练时是否更新某一层的权重\n",
    "        self.conv1 = _conv(3, 64, kernel_size=7, stride=2, padding=3, pad_mode='pad')\n",
    "        self.bn1 = _BatchNorm2dInit(64, affine=bn_training, use_batch_statistics=bn_training)\n",
    "        self.relu = ops.ReLU()\n",
    "        self.maxpool = ops.MaxPool(kernel_size=3, strides=2, pad_mode=\"SAME\")\n",
    "        self.weights_update = weights_update\n",
    "        \n",
    "        if not self.weights_update:\n",
    "            self.conv1.weight.requires_grad = False\n",
    "        \n",
    "        self.layer1 = self._make_layer(block, \n",
    "                                       layer_nums[0], \n",
    "                                       in_channel=in_channels[0], \n",
    "                                       out_channel=out_channels[0], \n",
    "                                       stride=1, \n",
    "                                       training=bn_training, \n",
    "                                       weights_update=self.weights_update)\n",
    "        self.layer2 = self._make_layer(block, \n",
    "                                       layer_nums[1], \n",
    "                                       in_channel=in_channels[1], \n",
    "                                       out_channel=out_channels[1], \n",
    "                                       stride=2, \n",
    "                                       training=bn_training, \n",
    "                                       weights_update=True)\n",
    "        self.layer3 = self._make_layer(block, \n",
    "                                       layer_nums[2], \n",
    "                                       in_channel=in_channels[2], \n",
    "                                       out_channel=out_channels[2], \n",
    "                                       stride=2, \n",
    "                                       training=bn_training, \n",
    "                                       weights_update=True)\n",
    "        self.layer4 = self._make_layer(block, \n",
    "                                       layer_nums[3], \n",
    "                                       in_channel=in_channels[3], \n",
    "                                       out_channel=out_channels[3], \n",
    "                                       stride=2, \n",
    "                                       training=bn_training, \n",
    "                                       weights_update=True)\n",
    "    def _make_layer(self, block, layer_num, in_channel, out_channel, stride, training=False, weights_update=False):\n",
    "        layers = []\n",
    "        down_sample = False\n",
    "        if stride != 1 or in_channel != out_channel:\n",
    "            down_sample = True\n",
    "        resblk = block(in_channel, out_channel, stride=stride, down_sample=down_sample, training=training, weights_update=weights_update)\n",
    "        layers.append(resblk)\n",
    "        \n",
    "        for _ in range(1, layer_num):\n",
    "            resblk = block(out_channel, out_channel, stride=1, training=training, weights_update=weights_update)\n",
    "            layers.append(resblk)\n",
    "        \n",
    "        return nn.SequentialCell(layers)\n",
    "    def construct(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        c1 = self.maxpool(x)\n",
    "        \n",
    "        c2 = self.layer1(c1)\n",
    "        identity = c2\n",
    "        if not self.weights_update:\n",
    "            identity = ops.stop_gradient(c2)\n",
    "        c3 = self.layer2(identity)\n",
    "        c4 = self.layer3(c3)\n",
    "        c5 = self.layer4(c4)\n",
    "\n",
    "        return identity, c3, c4, c5\n",
    "class ResidualBlock(nn.Cell):\n",
    "    expansion = 4\n",
    "    def __init__(self, in_channels, out_channels,stride=1,down_sample=False,momentum=0.1,training=False, weights_update=False):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.affine = weights_update\n",
    "        \n",
    "        out_chls = out_channels // self.expansion\n",
    "        self.conv1 = _conv(in_channels, out_chls, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn1 = _BatchNorm2dInit(out_chls, momentum=momentum, affine=self.affine, use_batch_statistics=training)\n",
    "        self.conv2 = _conv(out_chls, out_chls, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn2 = _BatchNorm2dInit(out_chls, momentum=momentum, affine=self.affine, use_batch_statistics=training)\n",
    "        self.conv3 = _conv(out_chls, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn3 = _BatchNorm2dInit(out_channels, momentum=momentum, affine=self.affine, use_batch_statistics=training)\n",
    "        \n",
    "        if training:\n",
    "            self.bn1 = self.bn1.set_train()\n",
    "            self.bn2 = self.bn2.set_train()\n",
    "            self.bn3 = self.bn3.set_train()\n",
    "        \n",
    "        if not weights_update:\n",
    "            self.conv1.weight.requires_grad = False\n",
    "            self.conv2.weight.requires_grad = False\n",
    "            self.conv3.weight.requires_grad = False\n",
    "        \n",
    "        self.relu = ops.ReLU()\n",
    "        self.downsample = down_sample\n",
    "        if self.downsample:\n",
    "            self.conv_down_sample = _conv(in_channels, out_channels, kernel_size=1, stride=stride, padding=0)\n",
    "            self.bn_down_sample = _BatchNorm2dInit(out_channels, momentum=momentum, affine=self.affine,\n",
    "                                                   use_batch_statistics=training)\n",
    "            if training:\n",
    "                self.bn_down_sample = self.bn_down_sample.set_train()\n",
    "            if not weights_update:\n",
    "                self.conv_down_sample.weight.requires_grad = False\n",
    "        self.add = ops.Add()\n",
    "    def construct(self, x):\n",
    "        identity = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        \n",
    "        if self.downsample:\n",
    "            identity = self.conv_down_sample(identity)\n",
    "            identity = self.bn_down_sample(identity)\n",
    "        \n",
    "        out = self.add(out, identity)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62daaf9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 256, 56, 56)\n",
      "(1, 512, 28, 28)\n",
      "(1, 1024, 14, 14)\n",
      "(1, 2048, 7, 7)\n"
     ]
    }
   ],
   "source": [
    "resnet = ResNetFea(ResidualBlock, [3, 4, 6, 3],[64, 256, 512, 1024],[256, 512, 1024, 2048],False)\n",
    "x = Tensor(np.random.rand(1, 3, 224, 224), ms.float32)\n",
    "x = resnet(x)\n",
    "for i in range(len(x)):\n",
    "    print(x[i].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dd2cf7",
   "metadata": {},
   "source": [
    "# FPN网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c2c46d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mindspore as ms\n",
    "import mindspore.ops as ops\n",
    "import mindspore.nn as nn\n",
    "from mindspore.common.tensor import Tensor\n",
    "\n",
    "def conv(in_channels, out_channels, kernel_size=3, stride=1, padding=0, pad_mode='pad'):\n",
    "    shape = (out_channels, in_channels, kernel_size, kernel_size)\n",
    "    weights = ms.common.initializer.initializer(\"XavierUniform\", shape=shape, dtype=ms.float32).init_data()\n",
    "    shape_bias = (out_channels,)\n",
    "    biass = Tensor(np.array(np.zeros(shape_bias).astype(np.float32)))\n",
    "    return nn.Conv2d(in_channels, out_channels,\n",
    "                     kernel_size=kernel_size, stride=stride, padding=padding,\n",
    "                     pad_mode=pad_mode, weight_init=weights, has_bias=True, bias_init=biass)\n",
    "\n",
    "\n",
    "class FeatPyramidNeck(nn.Cell):\n",
    "    def __init__(self, in_channels, out_channels, num_outs):\n",
    "        super(FeatPyramidNeck, self).__init__()\n",
    "        self.num_outs = num_outs\n",
    "        self.in_channels = in_channels\n",
    "        self.fpn_layer = len(self.in_channels)  # fpn_layer = 4\n",
    "\n",
    "        self.lateral_convs_list_ = []\n",
    "        self.fpn_convs_ = []\n",
    "\n",
    "        for _, channel in enumerate(in_channels):\n",
    "            l_conv = conv(channel, out_channels, kernel_size=1, stride=1, padding=0, pad_mode='valid')\n",
    "            fpn_conv = conv(out_channels, out_channels, kernel_size=3, stride=1, padding=0, pad_mode='same')\n",
    "            self.lateral_convs_list_.append(l_conv)\n",
    "            self.fpn_convs_.append(fpn_conv)\n",
    "        self.lateral_convs_list = nn.layer.CellList(self.lateral_convs_list_)  # 构建Cell列表,1*1的卷积，改变通道数\n",
    "        self.fpn_convs_list = nn.layer.CellList(self.fpn_convs_)  # 构建Cell列表\n",
    "        self.interpolate1 = ops.ResizeNearestNeighbor([48, 80])  # [48, 80]\n",
    "        self.interpolate2 = ops.ResizeNearestNeighbor([96, 160])  # [96, 160]\n",
    "        self.interpolate3 = ops.ResizeNearestNeighbor([192, 320])  # [192, 320]\n",
    "        self.maxpool = ops.MaxPool(kernel_size=1, strides=2, pad_mode=\"same\")\n",
    "\n",
    "    def construct(self, inputs):\n",
    "        x = ()\n",
    "        for i in range(self.fpn_layer):\n",
    "            x += (self.lateral_convs_list[i](inputs[i]),)\n",
    "\n",
    "        y = (x[3],)\n",
    "        y = y + (x[2] + self.interpolate1(y[self.fpn_layer - 4]),)\n",
    "        y = y + (x[1] + self.interpolate2(y[self.fpn_layer - 3]),)\n",
    "        y = y + (x[0] + self.interpolate3(y[self.fpn_layer - 2]),) # y中存的内容是从上到下的Pi\n",
    "\n",
    "        z = ()\n",
    "        for i in range(self.fpn_layer - 1, -1, -1):  # i : 3,2,1,0\n",
    "            z = z + (y[i],)  #  z中将y中的结果倒序，即从底到上\n",
    "\n",
    "        outs = ()\n",
    "        for i in range(self.fpn_layer):\n",
    "            outs = outs + (self.fpn_convs_list[i](z[i]),)\n",
    "\n",
    "        for i in range(self.num_outs - self.fpn_layer):\n",
    "            outs = outs + (self.maxpool(outs[3]),)\n",
    "        return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17eab488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 256, 192, 320)\n",
      "(1, 256, 96, 160)\n",
      "(1, 256, 48, 80)\n",
      "(1, 256, 24, 40)\n",
      "(1, 256, 12, 20)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    resnet = ResNetFea(ResidualBlock, [3, 4, 6, 3], [64, 256, 512, 1024], [256, 512, 1024, 2048], False)\n",
    "    x = Tensor(np.random.rand(1, 3, 768, 1280), ms.float32) # *\n",
    "    x = resnet(x)\n",
    "\n",
    "    neck = FeatPyramidNeck([256, 512, 1024, 2048], 256, 5)\n",
    "    res = neck(x)\n",
    "    for i in range(len(res)):\n",
    "        print(res[i].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5960f79",
   "metadata": {},
   "source": [
    "# rpn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda69cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mindspore as ms\n",
    "import mindspore.ops as ops\n",
    "import mindspore.nn as nn\n",
    "from mindspore import Tensor\n",
    "class RpnRegClsBlock(nn.Cell):\n",
    "    def __init__(self, in_channels, feat_channels, num_anchors, cls_out_channels,\n",
    "                weight_conv, bias_conv, weight_cls, bias_cls, weight_reg, bias_reg):\n",
    "        super(RpnRegClsBlock, self).__init__()\n",
    "        self.rpn_conv = nn.Conv2d(in_channels, feat_channels, kernel_size=3, stride=1, pad_mode='same',\n",
    "                                  has_bias=True, weight_init=weight_conv, bias_init=bias_conv)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.rpn_cls = nn.Conv2d(feat_channels, num_anchors * cls_out_channels, kernel_size=1, pad_mode='valid',\n",
    "                                 has_bias=True, weight_init=weight_cls, bias_init=bias_cls)\n",
    "        self.rpn_reg = nn.Conv2d(feat_channels, num_anchors * 4, kernel_size=1, pad_mode='valid',\n",
    "                                 has_bias=True, weight_init=weight_reg, bias_init=bias_reg)\n",
    "    def construct(self, x):\n",
    "        x = self.relu(self.rpn_conv(x))\n",
    "        x1 = self.rpn_cls(x)\n",
    "        x2 = self.rpn_reg(x)\n",
    "        \n",
    "        return x1, x2\n",
    "class RPN(nn.Cell):\n",
    "    def __init__(self, batch_size, in_channels, feat_channels, num_anchors, cls_out_channels):\n",
    "        super(RPN, self).__init__()\n",
    "        self.dtype = np.float32\n",
    "        self.ms_type = ms.float32\n",
    "        self.device_type = \"Others\"\n",
    "        self.num_bboxes = 245520\n",
    "        self.slice_index = ()\n",
    "        self.feature_anchor_shape = ()\n",
    "        self.slice_index += (0,)\n",
    "        index = 0\n",
    "        feature_shapes = [[192, 320], [96, 160], [48, 80], [24, 40], [12, 20]]\n",
    "        for shape in feature_shapes:\n",
    "            self.slice_index += (self.slice_index[index] + shape[0]*shape[1]*num_anchors)\n",
    "            self.feature_anchor_shape += (shape[0]*shape[1]*num_anchors*batch_size,)\n",
    "            index += 1\n",
    "        \n",
    "        self.num_anchors = num_anchors\n",
    "        self.batch_size = batch_size\n",
    "        self.test_batch_size = 2\n",
    "        self.num_layers = 5\n",
    "        self.real_ratio = ms.numpy.ones((1, 1), self.dtype)\n",
    "        \n",
    "        self.rpn_convs_list = nn.layer.CellList(self._make_rpn_layer(self.num_layers, in_channels, feat_channels,\n",
    "                                                                     num_anchors, cls_out_channels))\n",
    "    def _make_rpn_layer(self, num_layers, in_channels, feat_channels, num_anchors, cls_out_channels):\n",
    "        rpn_layer = []\n",
    "        # 3*3卷积，cls和reg初始化\n",
    "        shp_weight_conv = (feat_channels, in_channels, 3, 3)\n",
    "        shp_bias_conv = (feat_channels,)\n",
    "        weight_conv = ms.common.initializer.initializer('Normal', shape=shp_weight_conv, dtype=self.ms_type).init_data()\n",
    "        \n",
    "        shp_weight_cls = (num_anchors * cls_out_channels, feat_channels, 1, 1)\n",
    "        shp_bias_cls = (num_anchors * cls_out_channels,)\n",
    "        weight_cls = ms.common.initializer.initializer('Normal', shape=shp_weight_cls, dtype=self.ms_type).init_data()\n",
    "        bias_cls = ms.common.initializer.initializer(0, shape=shp_bias_cls, dtype=self.ms_type).init_data()\n",
    "        \n",
    "        shp_weight_reg = (num_anchors * 4, feat_channels, 1, 1)\n",
    "        shp_bias_reg = (num_anchors * 4,)\n",
    "        weight_reg = ms.common.initializer.initializer('Normal', shape=shp_weight_reg, dtype=self.ms_type).init_data()\n",
    "        bias_reg = ms.common.initializer.initializer(0, shape=shp_bias_reg, dtype=self.ms_type).init_data()\n",
    "        \n",
    "        for i in range(num_layers):\n",
    "            rpn_reg_cls_block = RpnRegClsBlock(in_channels, feat_channels, num_anchors, cls_out_channels, \\\n",
    "                                               weight_conv, bias_conv, weight_cls, \\\n",
    "                                               bias_cls, weight_reg, bias_reg)\n",
    "            rpn_layer.append(rpn_reg_cls_block)\n",
    "        \n",
    "        for i in range(1, num_layers):\n",
    "            \n",
    "    def construct(self, ):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af0282b",
   "metadata": {},
   "source": [
    "# Faster-RCNN主干网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5abd8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore.nn as nn\n",
    "import numpy as np\n",
    "class Faster_Rcnn(nn.Cell):\n",
    "    def __init__(self):\n",
    "        self.dtype = np.float32\n",
    "        self.ms_type = ms.float32\n",
    "        self.train_batch_size = 2  # 设置训练时的batch大小为2\n",
    "        self.without_bg_loss = True  # ?\n",
    "        self.num_classes = 4  # 设置预测类别的个数，算上了背景类别\n",
    "        self.num_cls_bbox = 3  # 设置类别框的个数，不预测背景的框\n",
    "        self.anchor_scales = [8]  # anchor尺寸\n",
    "        self.anchor_ratios = [0.5, 1.0, 2.0]  # anchor长宽比\n",
    "        self.anchor_strides = [4, 8, 16, 32, 64] # ?\n",
    "        self.target_means = tuple([0., 0., 0., 0.]) # ?\n",
    "        self.target_stds = tuple([0.1, 0.1, 0.2, 0.2]) # ?\n",
    "        \n",
    "        # 创建anchor生成器\n",
    "        self.anchor_base_sizes = list(self.anchor_strides)\n",
    "        self.anchor_generators = []\n",
    "        for anchor_base in self.anchor_base_sizes:\n",
    "            self.anchor_generators.append(AnchorGenerator(anchor_base, self.anchor_scales, self.anchor_ratios))\n",
    "        self.num_anchors = len(self.anchor_ratios) * len(self.anchor_scales)\n",
    "        featmap_sizes = [[192, 320], [96, 160], [48, 80], [24, 40], [12, 20]]\n",
    "        assert len(featmap_sizes) == len(self.anchor_generators)\n",
    "        self.anchor_list = self.get_anchors(featmap_sizes)\n",
    "        \n",
    "        # ResNet backbone\n",
    "        self.backbone = ResNetFea(ResidualBlock, [3,4,6,3], [64,256,512,1024], [256,512,1024,2048])\n",
    "        \n",
    "        # Fpn\n",
    "        self.fpn_neck = FeatPyramidNeck([256, 512, 1024, 2048], 256, 5)\n",
    "        \n",
    "        # Rpn and rpn loss\n",
    "        self.gt_labels_stage1 = Tensor(np.ones((self.train_batch_size, 128)).astype(np.uint8))\n",
    "        self.rpn_with_loss = RPN(self.train_batch_size, 256, 256, self.num_anchors, 1)\n",
    "        \n",
    "    def construct(self, img_data, img_metas, gt_bboxes, gt_labels, gt_valids):\n",
    "        x = self.backbone(img_data)\n",
    "        x = self.fpn_neck(x)\n",
    "        \n",
    "        rpn_loss, cls_score, bbox_pred, rpn_cls_loss, rpn_reg_loss, _ = self.rpn_with_loss(x,\n",
    "                                                                                           img_metas,\n",
    "                                                                                           self.anchor_list,\n",
    "                                                                                           gt_bboxes,\n",
    "                                                                                           self.gt_labels_stage1,\n",
    "                                                                                           gt_valids)\n",
    "        \n",
    "    def get_anchors(self, featmap_sizes):\n",
    "        num_levels = len(featmap_sizes)\n",
    "        multi_level_anchors = ()\n",
    "        for i in range(num_levels):\n",
    "            anchors = self.anchor_generators[i].grid_anchors(featmap_sizes[i], self.anchor_strides[i])\n",
    "            multi_level_anchors += (Tensor(anchors.astype(self.dtype)),)\n",
    "        \n",
    "        return multi_level_anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94348935",
   "metadata": {},
   "outputs": [],
   "source": [
    "(408, 575, 3)补充黑块\n",
    "(627, 640, 3)拉伸\n",
    "(640, 425, 3)拉伸\n",
    "(350, 640, 3)补充黑块\n",
    "(427, 640, 3)补充黑块\n",
    "(456, 640, 3)\n",
    "(480, 640, 3)\n",
    "(427, 640, 3)\n",
    "(428, 640, 3)\n",
    "(426, 640, 3)\n",
    "(359, 640, 3)\n",
    "(480, 640, 3)\n",
    "(480, 640, 3)\n",
    "(480, 640, 3)\n",
    "(427, 640, 3)\n",
    "(375, 640, 3)\n",
    "(427, 640, 3)\n",
    "(427, 640, 3)\n",
    "(427, 640, 3)\n",
    "(327, 500, 3)\n",
    "(640, 480, 3)\n",
    "(480, 640, 3)\n",
    "(480, 640, 3)\n",
    "(480, 640, 3)\n",
    "(441, 640, 3)\n",
    "(427, 640, 3)\n",
    "(399, 500, 3)\n",
    "(640, 427, 3)\n",
    "(494, 640, 3)\n",
    "(480, 640, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mindspore_py37] *",
   "language": "python",
   "name": "conda-env-mindspore_py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
