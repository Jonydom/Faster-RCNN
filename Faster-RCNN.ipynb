{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2534fe3",
   "metadata": {},
   "source": [
    "# 1）将coco2017数据集进行切分，生成minicoco2017数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8796ac21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fast script for the creation of a sub-set of the coco dataset in the form of a data folder.\n",
    "\n",
    "import json\n",
    "from pycocotools.coco import COCO\n",
    "import wget\n",
    "import numpy as np\n",
    "from random import sample\n",
    "from pathlib import Path\n",
    "from joblib import delayed, Parallel\n",
    "\n",
    "ANNOTATIONS = {\"info\": {\n",
    "    \"description\": \"minicoco2017\"\n",
    "}\n",
    "}\n",
    "\n",
    "def myImages(images: list, train: int, val: int) -> tuple:\n",
    "    myImagesTrain = images[:train]\n",
    "    myImagesVal = images[train:train+val]\n",
    "    return myImagesTrain, myImagesVal\n",
    "\n",
    "\n",
    "def cocoJson(images: list) -> dict:\n",
    "    arrayIds = np.array([k[\"id\"] for k in images])\n",
    "    annIds = coco.getAnnIds(imgIds=arrayIds, catIds=catIds, iscrowd=None)\n",
    "    anns = coco.loadAnns(annIds)\n",
    "    for k in anns:\n",
    "        k[\"category_id\"] = catIds.index(k[\"category_id\"])+1\n",
    "    catS = [{'id': int(value), 'name': key}\n",
    "            for key, value in categories.items()]\n",
    "    ANNOTATIONS[\"images\"] = images\n",
    "    ANNOTATIONS[\"annotations\"] = anns\n",
    "    ANNOTATIONS[\"categories\"] = catS\n",
    "\n",
    "    return ANNOTATIONS\n",
    "\n",
    "\n",
    "def createJson(JsonFile: json, train: bool) -> None:\n",
    "    name = \"train\"\n",
    "    if not train:\n",
    "        name = \"val\"\n",
    "    Path(\"minicoco2017/annotations\").mkdir(parents=True, exist_ok=True)\n",
    "    with open(f\"minicoco2017/annotations/{name}2017.json\", \"w\") as outfile:\n",
    "        json.dump(JsonFile, outfile)\n",
    "\n",
    "\n",
    "def downloadImagesToTrain(img: dict) -> None:\n",
    "    link = (img['coco_url'])\n",
    "    Path(\"minicoco2017/train2017\").mkdir(parents=True, exist_ok=True)\n",
    "    wget.download(link, f\"{'minicoco2017/train2017/' + img['file_name']}\")\n",
    "\n",
    "def downloadImagesToVal(img: dict) -> None:\n",
    "    link = (img['coco_url'])\n",
    "    Path(\"minicoco2017/val2017\").mkdir(parents=True, exist_ok=True)\n",
    "    wget.download(link, f\"{'minicoco2017/val2017/' + img['file_name']}\")\n",
    "\n",
    "# Instantiate COCO specifying the annotations json path; download here: https://cocodataset.org/#download\n",
    "coco = COCO('./coco2017/annotations/instances_train2017.json')\n",
    "\n",
    "# Specify a list of category names of interest\n",
    "catNms = ['car', 'airplane', 'person']\n",
    "\n",
    "catIds = coco.getCatIds(catNms)  # catIds: [1, 3, 5]\n",
    "\n",
    "dictCOCO = {k: coco.getCatIds(k)[0] for k in catNms}  # dictCOCO: {'car': 3, 'airplane': 5, 'person': 1}\n",
    "dictCOCOSorted = dict(sorted(dictCOCO.items(), key=lambda x: x[1]))  # dictCOCOSorted: {'person': 1, 'car': 3, 'airplane': 5}\n",
    "\n",
    "IdCategories = list(range(1, len(catNms)+1))  # IdCategories: [1, 2, 3]\n",
    "categories = dict(zip(list(dictCOCOSorted), IdCategories))  # categories: {'person': 1, 'car': 2, 'airplane': 3}\n",
    "\n",
    "# getCatIds return a sorted list of id.\n",
    "# For the creation of the json file in coco format, the list of ids must be successive 1, 2, 3..\n",
    "# So we reorganize the ids. In the cocoJson method we modify the values of the category_id parameter.\n",
    "\n",
    "# Get the corresponding image ids and images using loadImgs\n",
    "imgIds = coco.getImgIds(catIds=catIds)  # 根据物体类别得id号，得到训练集中对应img的id，这里一共173张\n",
    "imgOriginals = coco.loadImgs(imgIds)  # 返回list数组，数组中包含173个字典\n",
    "\n",
    "# The images are selected randomly\n",
    "imgShuffled = sample(imgOriginals, len(imgOriginals))  # 进行图片顺序打乱\n",
    "\n",
    "# Choose the number of images for the training and validation set. default 30-10\n",
    "myImagesTrain, myImagesVal = myImages(imgShuffled, 30, 10)  # imgShuffled前30个图片作为训练集，31-40作为验证集\n",
    "\n",
    "trainSet = cocoJson(myImagesTrain)\n",
    "createJson(trainSet, train=True)\n",
    "\n",
    "valSet = cocoJson(myImagesVal)\n",
    "createJson(valSet, train=False)\n",
    "\n",
    "Parallel(\n",
    "    n_jobs=-1, prefer=\"threads\")([delayed(downloadImagesToTrain)(img) for img in myImagesTrain])\n",
    "\n",
    "Parallel(\n",
    "    n_jobs=-1, prefer=\"threads\")([delayed(downloadImagesToVal)(img) for img in myImagesVal])\n",
    "\n",
    "print(\"\\nfinish.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d22510",
   "metadata": {},
   "source": [
    "# 2）将数据集转换为mindrecord数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "087a8a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nice\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2020-2022 Huawei Technologies Co., Ltd\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ============================================================================\n",
    "\n",
    "\"\"\"FasterRcnn dataset\"\"\"\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "\n",
    "import cv2\n",
    "import mindspore as ms\n",
    "import mindspore.dataset as de\n",
    "from mindspore.mindrecord import FileWriter\n",
    "\n",
    "\n",
    "def bbox_overlaps(bboxes1, bboxes2, mode='iou'):\n",
    "    \"\"\"Calculate the ious between each bbox of bboxes1 and bboxes2.\n",
    "\n",
    "    Args:\n",
    "        bboxes1(ndarray): shape (n, 4)\n",
    "        bboxes2(ndarray): shape (k, 4)\n",
    "        mode(str): iou (intersection over union) or iof (intersection\n",
    "            over foreground)\n",
    "\n",
    "    Returns:\n",
    "        ious(ndarray): shape (n, k)\n",
    "    \"\"\"\n",
    "\n",
    "    assert mode in ['iou', 'iof']\n",
    "\n",
    "    bboxes1 = bboxes1.astype(np.float32)\n",
    "    bboxes2 = bboxes2.astype(np.float32)\n",
    "    rows = bboxes1.shape[0]\n",
    "    cols = bboxes2.shape[0]\n",
    "    ious = np.zeros((rows, cols), dtype=np.float32)\n",
    "    if rows * cols == 0:\n",
    "        return ious\n",
    "    exchange = False\n",
    "    if bboxes1.shape[0] > bboxes2.shape[0]:\n",
    "        bboxes1, bboxes2 = bboxes2, bboxes1\n",
    "        ious = np.zeros((cols, rows), dtype=np.float32)\n",
    "        exchange = True\n",
    "    area1 = (bboxes1[:, 2] - bboxes1[:, 0] + 1) * (bboxes1[:, 3] - bboxes1[:, 1] + 1)\n",
    "    area2 = (bboxes2[:, 2] - bboxes2[:, 0] + 1) * (bboxes2[:, 3] - bboxes2[:, 1] + 1)\n",
    "    for i in range(bboxes1.shape[0]):\n",
    "        x_start = np.maximum(bboxes1[i, 0], bboxes2[:, 0])\n",
    "        y_start = np.maximum(bboxes1[i, 1], bboxes2[:, 1])\n",
    "        x_end = np.minimum(bboxes1[i, 2], bboxes2[:, 2])\n",
    "        y_end = np.minimum(bboxes1[i, 3], bboxes2[:, 3])\n",
    "        overlap = np.maximum(x_end - x_start + 1, 0) * np.maximum(\n",
    "            y_end - y_start + 1, 0)\n",
    "        if mode == 'iou':\n",
    "            union = area1[i] + area2 - overlap\n",
    "        else:\n",
    "            union = area1[i] if not exchange else area2\n",
    "        ious[i, :] = overlap / union\n",
    "    if exchange:\n",
    "        ious = ious.T\n",
    "    return ious\n",
    "\n",
    "# 类：照片度量失真\n",
    "class PhotoMetricDistortion:\n",
    "    \"\"\"Photo Metric Distortion\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 brightness_delta=32,\n",
    "                 contrast_range=(0.5, 1.5),\n",
    "                 saturation_range=(0.5, 1.5),\n",
    "                 hue_delta=18):\n",
    "        self.brightness_delta = brightness_delta\n",
    "        self.contrast_lower, self.contrast_upper = contrast_range\n",
    "        self.saturation_lower, self.saturation_upper = saturation_range\n",
    "        self.hue_delta = hue_delta\n",
    "\n",
    "    def __call__(self, img, boxes, labels):\n",
    "        # random brightness\n",
    "        img = img.astype('float32')\n",
    "\n",
    "        if random.randint(2):\n",
    "            delta = random.uniform(-self.brightness_delta,\n",
    "                                   self.brightness_delta)\n",
    "            img += delta\n",
    "\n",
    "        # mode == 0 --> do random contrast first\n",
    "        # mode == 1 --> do random contrast last\n",
    "        mode = random.randint(2)\n",
    "        if mode == 1:\n",
    "            if random.randint(2):\n",
    "                alpha = random.uniform(self.contrast_lower,\n",
    "                                       self.contrast_upper)\n",
    "                img *= alpha\n",
    "\n",
    "        # convert color from BGR to HSV\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        # random saturation\n",
    "        if random.randint(2):\n",
    "            img[..., 1] *= random.uniform(self.saturation_lower,\n",
    "                                          self.saturation_upper)\n",
    "\n",
    "        # random hue\n",
    "        if random.randint(2):\n",
    "            img[..., 0] += random.uniform(-self.hue_delta, self.hue_delta)\n",
    "            img[..., 0][img[..., 0] > 360] -= 360\n",
    "            img[..., 0][img[..., 0] < 0] += 360\n",
    "\n",
    "        # convert color from HSV to BGR\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "        # random contrast\n",
    "        if mode == 0:\n",
    "            if random.randint(2):\n",
    "                alpha = random.uniform(self.contrast_lower,\n",
    "                                       self.contrast_upper)\n",
    "                img *= alpha\n",
    "\n",
    "        # randomly swap channels\n",
    "        if random.randint(2):\n",
    "            img = img[..., random.permutation(3)]\n",
    "\n",
    "        return img, boxes, labels\n",
    "\n",
    "\n",
    "class Expand:\n",
    "    \"\"\"expand image\"\"\"\n",
    "\n",
    "    def __init__(self, mean=(0, 0, 0), to_rgb=True, ratio_range=(1, 4)):\n",
    "        if to_rgb:\n",
    "            self.mean = mean[::-1]\n",
    "        else:\n",
    "            self.mean = mean\n",
    "        self.min_ratio, self.max_ratio = ratio_range\n",
    "\n",
    "    def __call__(self, img, boxes, labels):\n",
    "        if random.randint(2):\n",
    "            return img, boxes, labels\n",
    "\n",
    "        h, w, c = img.shape\n",
    "        ratio = random.uniform(self.min_ratio, self.max_ratio)\n",
    "        expand_img = np.full((int(h * ratio), int(w * ratio), c),\n",
    "                             self.mean).astype(img.dtype)\n",
    "        left = int(random.uniform(0, w * ratio - w))\n",
    "        top = int(random.uniform(0, h * ratio - h))\n",
    "        expand_img[top:top + h, left:left + w] = img\n",
    "        img = expand_img\n",
    "        boxes += np.tile((left, top), 2)\n",
    "        return img, boxes, labels\n",
    "\n",
    "\n",
    "def rescale_with_tuple(img, scale):\n",
    "    h, w = img.shape[:2]\n",
    "    scale_factor = min(max(scale) / max(h, w), min(scale) / min(h, w))\n",
    "    new_size = int(w * float(scale_factor) + 0.5), int(h * float(scale_factor) + 0.5)\n",
    "    rescaled_img = cv2.resize(img, new_size, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    return rescaled_img, scale_factor\n",
    "\n",
    "\n",
    "def rescale_with_factor(img, scale_factor):\n",
    "    h, w = img.shape[:2]\n",
    "    new_size = int(w * float(scale_factor) + 0.5), int(h * float(scale_factor) + 0.5)\n",
    "    return cv2.resize(img, new_size, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "\n",
    "def rescale_column(img, img_shape, gt_bboxes, gt_label, gt_num, config):\n",
    "    \"\"\"rescale operation for image\"\"\"\n",
    "    img_data, scale_factor = rescale_with_tuple(img, (config.img_width, config.img_height))\n",
    "    if img_data.shape[0] > config.img_height:\n",
    "        img_data, scale_factor2 = rescale_with_tuple(img_data, (config.img_height, config.img_height))\n",
    "        scale_factor = scale_factor * scale_factor2\n",
    "\n",
    "    gt_bboxes = gt_bboxes * scale_factor\n",
    "    gt_bboxes[:, 0::2] = np.clip(gt_bboxes[:, 0::2], 0, img_data.shape[1] - 1)\n",
    "    gt_bboxes[:, 1::2] = np.clip(gt_bboxes[:, 1::2], 0, img_data.shape[0] - 1)\n",
    "\n",
    "    pad_h = config.img_height - img_data.shape[0]\n",
    "    pad_w = config.img_width - img_data.shape[1]\n",
    "    assert ((pad_h >= 0) and (pad_w >= 0))\n",
    "\n",
    "    pad_img_data = np.zeros((config.img_height, config.img_width, 3)).astype(img_data.dtype)\n",
    "    pad_img_data[0:img_data.shape[0], 0:img_data.shape[1], :] = img_data\n",
    "\n",
    "    img_shape = (config.img_height, config.img_width, 1.0)\n",
    "    img_shape = np.asarray(img_shape, dtype=np.float32)\n",
    "\n",
    "    return (pad_img_data, img_shape, gt_bboxes, gt_label, gt_num)\n",
    "\n",
    "\n",
    "def rescale_column_test(img, img_shape, gt_bboxes, gt_label, gt_num, config):\n",
    "    \"\"\"rescale operation for image of eval\"\"\"\n",
    "    img_data, scale_factor = rescale_with_tuple(img, (config.img_width, config.img_height))\n",
    "    if img_data.shape[0] > config.img_height:\n",
    "        img_data, scale_factor2 = rescale_with_tuple(img_data, (config.img_height, config.img_height))\n",
    "        scale_factor = scale_factor * scale_factor2\n",
    "\n",
    "    pad_h = config.img_height - img_data.shape[0]\n",
    "    pad_w = config.img_width - img_data.shape[1]\n",
    "    assert ((pad_h >= 0) and (pad_w >= 0))\n",
    "\n",
    "    pad_img_data = np.zeros((config.img_height, config.img_width, 3)).astype(img_data.dtype)\n",
    "    pad_img_data[0:img_data.shape[0], 0:img_data.shape[1], :] = img_data\n",
    "\n",
    "    img_shape = np.append(img_shape, (scale_factor, scale_factor))\n",
    "    img_shape = np.asarray(img_shape, dtype=np.float32)\n",
    "\n",
    "    return (pad_img_data, img_shape, gt_bboxes, gt_label, gt_num)\n",
    "\n",
    "\n",
    "def resize_column(img, img_shape, gt_bboxes, gt_label, gt_num, config):\n",
    "    \"\"\"resize operation for image\"\"\"\n",
    "    img_data = img\n",
    "    h, w = img_data.shape[:2]\n",
    "    img_data = cv2.resize(\n",
    "        img_data, (config.img_width, config.img_height), interpolation=cv2.INTER_LINEAR)\n",
    "    h_scale = config.img_height / h\n",
    "    w_scale = config.img_width / w\n",
    "\n",
    "    scale_factor = np.array(\n",
    "        [w_scale, h_scale, w_scale, h_scale], dtype=np.float32)\n",
    "    img_shape = (config.img_height, config.img_width, 1.0)\n",
    "    img_shape = np.asarray(img_shape, dtype=np.float32)\n",
    "\n",
    "    gt_bboxes = gt_bboxes * scale_factor\n",
    "\n",
    "    gt_bboxes[:, 0::2] = np.clip(gt_bboxes[:, 0::2], 0, img_shape[1] - 1)\n",
    "    gt_bboxes[:, 1::2] = np.clip(gt_bboxes[:, 1::2], 0, img_shape[0] - 1)\n",
    "\n",
    "    return (img_data, img_shape, gt_bboxes, gt_label, gt_num)\n",
    "\n",
    "\n",
    "def resize_column_test(img, img_shape, gt_bboxes, gt_label, gt_num, config):\n",
    "    \"\"\"resize operation for image of eval\"\"\"\n",
    "    img_data = img\n",
    "    h, w = img_data.shape[:2]\n",
    "    img_data = cv2.resize(\n",
    "        img_data, (config.img_width, config.img_height), interpolation=cv2.INTER_LINEAR)\n",
    "    h_scale = config.img_height / h\n",
    "    w_scale = config.img_width / w\n",
    "\n",
    "    scale_factor = np.array(\n",
    "        [w_scale, h_scale, w_scale, h_scale], dtype=np.float32)\n",
    "    img_shape = np.append(img_shape, (h_scale, w_scale))\n",
    "    img_shape = np.asarray(img_shape, dtype=np.float32)\n",
    "\n",
    "    gt_bboxes = gt_bboxes * scale_factor\n",
    "\n",
    "    gt_bboxes[:, 0::2] = np.clip(gt_bboxes[:, 0::2], 0, img_shape[1] - 1)\n",
    "    gt_bboxes[:, 1::2] = np.clip(gt_bboxes[:, 1::2], 0, img_shape[0] - 1)\n",
    "\n",
    "    return (img_data, img_shape, gt_bboxes, gt_label, gt_num)\n",
    "\n",
    "\n",
    "def impad_to_multiple_column(img, img_shape, gt_bboxes, gt_label, gt_num, config):\n",
    "    \"\"\"impad operation for image\"\"\"\n",
    "    img_data = cv2.copyMakeBorder(img,\n",
    "                                  0, config.img_height - img.shape[0], 0, config.img_width - img.shape[1],\n",
    "                                  cv2.BORDER_CONSTANT,\n",
    "                                  value=0)\n",
    "    img_data = img_data.astype(np.float32)\n",
    "    return (img_data, img_shape, gt_bboxes, gt_label, gt_num)\n",
    "\n",
    "\n",
    "def imnormalize_column(img, img_shape, gt_bboxes, gt_label, gt_num):\n",
    "    \"\"\"imnormalize operation for image\"\"\"\n",
    "    # Computed from random subset of ImageNet training images\n",
    "    mean = np.asarray([123.675, 116.28, 103.53])\n",
    "    std = np.asarray([58.395, 57.12, 57.375])\n",
    "    img_data = img.copy().astype(np.float32)\n",
    "    cv2.cvtColor(img_data, cv2.COLOR_BGR2RGB, img_data)  # inplace\n",
    "    cv2.subtract(img_data, np.float64(mean.reshape(1, -1)), img_data)  # inplace\n",
    "    cv2.multiply(img_data, 1 / np.float64(std.reshape(1, -1)), img_data)  # inplace\n",
    "\n",
    "    img_data = img_data.astype(np.float32)\n",
    "    return (img_data, img_shape, gt_bboxes, gt_label, gt_num)\n",
    "\n",
    "\n",
    "def flip_column(img, img_shape, gt_bboxes, gt_label, gt_num):\n",
    "    \"\"\"flip operation for image\"\"\"\n",
    "    img_data = img\n",
    "    img_data = np.flip(img_data, axis=1)\n",
    "    flipped = gt_bboxes.copy()\n",
    "    _, w, _ = img_data.shape\n",
    "\n",
    "    flipped[..., 0::4] = w - gt_bboxes[..., 2::4] - 1\n",
    "    flipped[..., 2::4] = w - gt_bboxes[..., 0::4] - 1\n",
    "\n",
    "    return (img_data, img_shape, flipped, gt_label, gt_num)\n",
    "\n",
    "\n",
    "def transpose_column(img, img_shape, gt_bboxes, gt_label, gt_num):\n",
    "    \"\"\"transpose operation for image\"\"\"\n",
    "    img_data = img.transpose(2, 0, 1).copy()\n",
    "    img_data = img_data.astype(np.float32)\n",
    "    img_shape = img_shape.astype(np.float32)\n",
    "    gt_bboxes = gt_bboxes.astype(np.float32)\n",
    "    gt_label = gt_label.astype(np.int32)\n",
    "    gt_num = gt_num.astype(np.bool)\n",
    "\n",
    "    return (img_data, img_shape, gt_bboxes, gt_label, gt_num)\n",
    "\n",
    "\n",
    "def photo_crop_column(img, img_shape, gt_bboxes, gt_label, gt_num):\n",
    "    \"\"\"photo crop operation for image\"\"\"\n",
    "    random_photo = PhotoMetricDistortion()\n",
    "    img_data, gt_bboxes, gt_label = random_photo(img, gt_bboxes, gt_label)\n",
    "\n",
    "    return (img_data, img_shape, gt_bboxes, gt_label, gt_num)\n",
    "\n",
    "\n",
    "def expand_column(img, img_shape, gt_bboxes, gt_label, gt_num):\n",
    "    \"\"\"expand operation for image\"\"\"\n",
    "    expand = Expand()\n",
    "    img, gt_bboxes, gt_label = expand(img, gt_bboxes, gt_label)\n",
    "\n",
    "    return (img, img_shape, gt_bboxes, gt_label, gt_num)\n",
    "\n",
    "\n",
    "def preprocess_fn(image, box, is_training, config):\n",
    "    \"\"\"Preprocess function for dataset.\"\"\"\n",
    "\n",
    "    def _infer_data(image_bgr, image_shape, gt_box_new, gt_label_new, gt_iscrowd_new_revert):\n",
    "        image_shape = image_shape[:2]\n",
    "        input_data = image_bgr, image_shape, gt_box_new, gt_label_new, gt_iscrowd_new_revert\n",
    "\n",
    "        if config.keep_ratio:\n",
    "            input_data = rescale_column_test(*input_data, config=config)\n",
    "        else:\n",
    "            input_data = resize_column_test(*input_data, config=config)\n",
    "        input_data = imnormalize_column(*input_data)\n",
    "\n",
    "        output_data = transpose_column(*input_data)\n",
    "        return output_data\n",
    "\n",
    "    def _data_aug(image, box, is_training):\n",
    "        \"\"\"Data augmentation function.\"\"\"\n",
    "        pad_max_number = config.num_gts\n",
    "        if pad_max_number < box.shape[0]:\n",
    "            box = box[:pad_max_number, :]\n",
    "        image_bgr = image.copy()\n",
    "        image_bgr[:, :, 0] = image[:, :, 2]\n",
    "        image_bgr[:, :, 1] = image[:, :, 1]\n",
    "        image_bgr[:, :, 2] = image[:, :, 0]\n",
    "        image_shape = image_bgr.shape[:2]\n",
    "        gt_box = box[:, :4]\n",
    "        gt_label = box[:, 4]\n",
    "        gt_iscrowd = box[:, 5]\n",
    "\n",
    "        gt_box_new = np.pad(gt_box, ((0, pad_max_number - box.shape[0]), (0, 0)), mode=\"constant\", constant_values=0)\n",
    "        gt_label_new = np.pad(gt_label, ((0, pad_max_number - box.shape[0])), mode=\"constant\", constant_values=-1)\n",
    "        gt_iscrowd_new = np.pad(gt_iscrowd, ((0, pad_max_number - box.shape[0])), mode=\"constant\", constant_values=1)\n",
    "        gt_iscrowd_new_revert = (~(gt_iscrowd_new.astype(np.bool))).astype(np.int32)\n",
    "\n",
    "        if not is_training:\n",
    "            return _infer_data(image_bgr, image_shape, gt_box_new, gt_label_new, gt_iscrowd_new_revert)\n",
    "\n",
    "        flip = (np.random.rand() < config.flip_ratio)\n",
    "        expand = (np.random.rand() < config.expand_ratio)\n",
    "        input_data = image_bgr, image_shape, gt_box_new, gt_label_new, gt_iscrowd_new_revert\n",
    "\n",
    "        if expand:\n",
    "            input_data = expand_column(*input_data)\n",
    "        if config.keep_ratio:\n",
    "            input_data = rescale_column(*input_data, config=config)\n",
    "        else:\n",
    "            input_data = resize_column(*input_data, config=config)\n",
    "        input_data = imnormalize_column(*input_data)\n",
    "        if flip:\n",
    "            input_data = flip_column(*input_data)\n",
    "\n",
    "        output_data = transpose_column(*input_data)\n",
    "        return output_data\n",
    "\n",
    "    return _data_aug(image, box, is_training)\n",
    "\n",
    "\n",
    "def create_coco_label(is_training, config):\n",
    "    \"\"\"Get image path and annotation from COCO.\"\"\"\n",
    "    from pycocotools.coco import COCO\n",
    "\n",
    "    coco_root = config.coco_root  # coco_root: \"./minicoco2017\"\n",
    "    data_type = config.val_data_type\n",
    "    if is_training:\n",
    "        data_type = config.train_data_type  # train_data_type: \"train2017\"\n",
    "\n",
    "    # Classes need to train or test.\n",
    "    train_cls = config.coco_classes  # coco_classes: ['person','car', 'airplane']\n",
    "    train_cls_dict = {}\n",
    "    for i, cls in enumerate(train_cls):\n",
    "        train_cls_dict[cls] = i  # train_cls_dict: {'person': 0, 'airplane': 1, 'car': 2}\n",
    "\n",
    "    anno_json = os.path.join('.', coco_root, config.instance_set.format(data_type))  # anno_json: \"../minicoco2017/annotations/train2017.json\"\n",
    "    if hasattr(config, 'train_set') and is_training:\n",
    "        anno_json = os.path.join(coco_root, config.train_set)\n",
    "    if hasattr(config, 'val_set') and not is_training:\n",
    "        anno_json = os.path.join(coco_root, config.val_set)\n",
    "\n",
    "    # 根据annotations json文件创建COCO类\n",
    "    coco = COCO(anno_json)\n",
    "    classs_dict = {}\n",
    "    cat_ids = coco.loadCats(coco.getCatIds()) # 获取所有的类别信息，loadCats()需要传入 需加载的类别id序列\n",
    "    for cat in cat_ids:\n",
    "        classs_dict[cat[\"id\"]] = cat[\"name\"] # classes_dict: {1:'person', 2:'car'...}\n",
    "\n",
    "    image_ids = coco.getImgIds() # 获取所有 标记所对应的原图id  image_ids: [391895, 522418...]\n",
    "    # 创建要返回的变量\n",
    "    image_files = []\n",
    "    image_anno_dict = {}\n",
    "\n",
    "    for img_id in image_ids:\n",
    "        image_info = coco.loadImgs(img_id)\n",
    "        file_name = image_info[0][\"file_name\"]\n",
    "        anno_ids = coco.getAnnIds(imgIds=img_id, iscrowd=None)\n",
    "        anno = coco.loadAnns(anno_ids)\n",
    "        image_path = os.path.join(coco_root, data_type, file_name)\n",
    "        annos = []\n",
    "        for label in anno:\n",
    "            bbox = label[\"bbox\"]\n",
    "            class_name = classs_dict[label[\"category_id\"]]\n",
    "            if class_name in train_cls:\n",
    "                x1, x2 = bbox[0], bbox[0] + bbox[2]\n",
    "                y1, y2 = bbox[1], bbox[1] + bbox[3]\n",
    "                annos.append([x1, y1, x2, y2] + [train_cls_dict[class_name]] + [int(label[\"iscrowd\"])])\n",
    "\n",
    "        image_files.append(image_path)\n",
    "        if annos:\n",
    "            image_anno_dict[image_path] = np.array(annos)\n",
    "        else:\n",
    "            image_anno_dict[image_path] = np.array([0, 0, 0, 0, 0, 1])\n",
    "\n",
    "    return image_files, image_anno_dict\n",
    "\n",
    "# 可能用于评估\n",
    "def parse_json_annos_from_txt(anno_file, config):\n",
    "    \"\"\"for user defined annotations text file, parse it to json format data\"\"\"\n",
    "    if not os.path.isfile(anno_file):\n",
    "        raise RuntimeError(\"Evaluation annotation file {} is not valid.\".format(anno_file))\n",
    "\n",
    "    annos = {\n",
    "        \"images\": [],\n",
    "        \"annotations\": [],\n",
    "        \"categories\": []\n",
    "    }\n",
    "\n",
    "    # set categories field\n",
    "    for i, cls_name in enumerate(config.coco_classes):\n",
    "        annos[\"categories\"].append({\"id\": i, \"name\": cls_name})\n",
    "\n",
    "    with open(anno_file, \"rb\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    img_id = 1\n",
    "    anno_id = 1\n",
    "    for line in lines:\n",
    "        line_str = line.decode(\"utf-8\").strip()\n",
    "        line_split = str(line_str).split(' ')\n",
    "        # set image field\n",
    "        file_name = line_split[0]\n",
    "        annos[\"images\"].append({\"file_name\": file_name, \"id\": img_id})\n",
    "        # set annotations field\n",
    "        for anno_info in line_split[1:]:\n",
    "            anno = anno_info.split(\",\")\n",
    "            x = float(anno[0])\n",
    "            y = float(anno[1])\n",
    "            w = float(anno[2]) - float(anno[0])\n",
    "            h = float(anno[3]) - float(anno[1])\n",
    "            category_id = int(anno[4])\n",
    "            iscrowd = int(anno[5])\n",
    "            annos[\"annotations\"].append({\"bbox\": [x, y, w, h],\n",
    "                                         \"area\": w * h,\n",
    "                                         \"category_id\": category_id,\n",
    "                                         \"iscrowd\": iscrowd,\n",
    "                                         \"image_id\": img_id,\n",
    "                                         \"id\": anno_id})\n",
    "            anno_id += 1\n",
    "        img_id += 1\n",
    "\n",
    "    return annos\n",
    "\n",
    "\n",
    "def create_train_data_from_txt(image_dir, anno_path):\n",
    "    \"\"\"Filter valid image file, which both in image_dir and anno_path.\"\"\"\n",
    "\n",
    "    def anno_parser(annos_str):\n",
    "        \"\"\"Parse annotation from string to list.\"\"\"\n",
    "        annos = []\n",
    "        for anno_str in annos_str:\n",
    "            anno = anno_str.strip().split(\",\")\n",
    "            xmin, ymin, xmax, ymax = list(map(float, anno[:4]))\n",
    "            cls_id = int(anno[4])\n",
    "            iscrowd = int(anno[5])\n",
    "            annos.append([xmin, ymin, xmax, ymax, cls_id, iscrowd])\n",
    "        return annos\n",
    "\n",
    "    image_files = []\n",
    "    image_anno_dict = {}\n",
    "    if not os.path.isdir(image_dir):\n",
    "        raise RuntimeError(\"Path given is not valid.\")\n",
    "    if not os.path.isfile(anno_path):\n",
    "        raise RuntimeError(\"Annotation file is not valid.\")\n",
    "\n",
    "    with open(anno_path, \"rb\") as f:\n",
    "        lines = f.readlines()\n",
    "    for line in lines:\n",
    "        line_str = line.decode(\"utf-8\").strip()\n",
    "        line_split = str(line_str).split(' ')\n",
    "        file_name = line_split[0]\n",
    "        image_path = os.path.join(image_dir, file_name)\n",
    "        if os.path.isfile(image_path):\n",
    "            image_anno_dict[image_path] = anno_parser(line_split[1:])\n",
    "            image_files.append(image_path)\n",
    "    return image_files, image_anno_dict\n",
    "\n",
    "\n",
    "def data_to_mindrecord_byte_image(config, dataset=\"coco\", is_training=True, prefix=\"fasterrcnn.mindrecord\", file_num=1):\n",
    "    \"\"\"Create MindRecord file.\"\"\"\n",
    "    mindrecord_dir = config.mindrecord_dir  # mindrecord_dir: \"./MindRecord_COCO_TRAIN\"\n",
    "    mindrecord_path = os.path.join(mindrecord_dir, prefix)  # mindrecord_file: \"/MindRecord_COCO_TRAIN/FasterRcnn.mindrecord0\"\n",
    "    writer = FileWriter(mindrecord_path, file_num)\n",
    "    if dataset == \"coco\":\n",
    "        image_files, image_anno_dict = create_coco_label(is_training, config=config)\n",
    "    else:\n",
    "        image_files, image_anno_dict = create_train_data_from_txt(config.image_dir, config.anno_path)\n",
    "\n",
    "    fasterrcnn_json = {\n",
    "        \"image\": {\"type\": \"bytes\"},\n",
    "        \"annotation\": {\"type\": \"int32\", \"shape\": [-1, 6]},\n",
    "    }\n",
    "    writer.add_schema(fasterrcnn_json, \"fasterrcnn_json\")\n",
    "\n",
    "    for image_name in image_files:\n",
    "        with open(image_name, 'rb') as f:\n",
    "            img = f.read()\n",
    "        annos = np.array(image_anno_dict[image_name], dtype=np.int32)\n",
    "        row = {\"image\": img, \"annotation\": annos}\n",
    "        writer.write_raw_data([row])\n",
    "    writer.commit()\n",
    "\n",
    "\n",
    "def create_fasterrcnn_dataset(config, mindrecord_file, batch_size=2, device_num=1, rank_id=0, is_training=True,\n",
    "                              num_parallel_workers=8, python_multiprocessing=False):\n",
    "    \"\"\"Create FasterRcnn dataset with MindDataset.\"\"\"\n",
    "    cv2.setNumThreads(0)\n",
    "    de.config.set_prefetch_size(1)\n",
    "    ds = de.MindDataset(mindrecord_file, columns_list=[\"image\", \"annotation\"], num_shards=device_num, shard_id=rank_id,\n",
    "                        num_parallel_workers=4, shuffle=is_training)\n",
    "    decode = ms.dataset.vision.Decode()\n",
    "    ds = ds.map(input_columns=[\"image\"], operations=decode)\n",
    "    compose_map_func = (lambda image, annotation: preprocess_fn(image, annotation, is_training, config=config))\n",
    "\n",
    "    if is_training:\n",
    "        ds = ds.map(input_columns=[\"image\", \"annotation\"],\n",
    "                    output_columns=[\"image\", \"image_shape\", \"box\", \"label\", \"valid_num\"],\n",
    "                    column_order=[\"image\", \"image_shape\", \"box\", \"label\", \"valid_num\"],\n",
    "                    operations=compose_map_func, python_multiprocessing=python_multiprocessing,\n",
    "                    num_parallel_workers=num_parallel_workers)\n",
    "        ds = ds.batch(batch_size, drop_remainder=True)\n",
    "    else:\n",
    "        ds = ds.map(input_columns=[\"image\", \"annotation\"],\n",
    "                    output_columns=[\"image\", \"image_shape\", \"box\", \"label\", \"valid_num\"],\n",
    "                    column_order=[\"image\", \"image_shape\", \"box\", \"label\", \"valid_num\"],\n",
    "                    operations=compose_map_func,\n",
    "                    num_parallel_workers=num_parallel_workers)\n",
    "        ds = ds.batch(batch_size, drop_remainder=True)\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfa1e25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mindspore_py37] *",
   "language": "python",
   "name": "conda-env-mindspore_py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
