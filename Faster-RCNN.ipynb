{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2534fe3",
   "metadata": {},
   "source": [
    "# 1）将coco2017数据集进行切分，生成minicoco2017数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8796ac21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=19.73s)\n",
      "creating index...\n",
      "index created!\n",
      "100% [............................................................................] 236406 / 236406\n",
      "finish.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pycocotools.coco import COCO\n",
    "import wget\n",
    "import numpy as np\n",
    "from random import sample\n",
    "from pathlib import Path\n",
    "from joblib import delayed, Parallel\n",
    "\n",
    "ANNOTATIONS = {\"info\": {\n",
    "    \"description\": \"minicoco2017\"\n",
    "}\n",
    "}\n",
    "\n",
    "def myImages(images: list, train: int, val: int) -> tuple:\n",
    "    myImagesTrain = images[:train]\n",
    "    myImagesVal = images[train:train+val]\n",
    "    return myImagesTrain, myImagesVal\n",
    "\n",
    "\n",
    "def cocoJson(images: list) -> dict:\n",
    "    arrayIds = np.array([k[\"id\"] for k in images])\n",
    "    annIds = coco.getAnnIds(imgIds=arrayIds, catIds=catIds, iscrowd=None)\n",
    "    anns = coco.loadAnns(annIds)\n",
    "    for k in anns:\n",
    "        k[\"category_id\"] = catIds.index(k[\"category_id\"])+1\n",
    "    catS = [{'id': int(value), 'name': key}\n",
    "            for key, value in categories.items()]\n",
    "    ANNOTATIONS[\"images\"] = images\n",
    "    ANNOTATIONS[\"annotations\"] = anns\n",
    "    ANNOTATIONS[\"categories\"] = catS\n",
    "\n",
    "    return ANNOTATIONS\n",
    "\n",
    "\n",
    "def createJson(JsonFile: json, train: bool) -> None:\n",
    "    name = \"train\"\n",
    "    if not train:\n",
    "        name = \"val\"\n",
    "    Path(\"minicoco2017/annotations\").mkdir(parents=True, exist_ok=True)\n",
    "    with open(f\"minicoco2017/annotations/{name}2017.json\", \"w\") as outfile:\n",
    "        json.dump(JsonFile, outfile)\n",
    "\n",
    "\n",
    "def downloadImagesToTrain(img: dict) -> None:\n",
    "    link = (img['coco_url'])\n",
    "    Path(\"minicoco2017/train2017\").mkdir(parents=True, exist_ok=True)\n",
    "    wget.download(link, f\"{'minicoco2017/train2017/' + img['file_name']}\")\n",
    "\n",
    "def downloadImagesToVal(img: dict) -> None:\n",
    "    link = (img['coco_url'])\n",
    "    Path(\"minicoco2017/val2017\").mkdir(parents=True, exist_ok=True)\n",
    "    wget.download(link, f\"{'minicoco2017/val2017/' + img['file_name']}\")\n",
    "\n",
    "coco = COCO('./coco2017/annotations/instances_train2017.json')\n",
    "\n",
    "catNms = ['car', 'airplane', 'person']\n",
    "\n",
    "catIds = coco.getCatIds(catNms) \n",
    "\n",
    "dictCOCO = {k: coco.getCatIds(k)[0] for k in catNms}  \n",
    "dictCOCOSorted = dict(sorted(dictCOCO.items(), key=lambda x: x[1]))  \n",
    "\n",
    "IdCategories = list(range(1, len(catNms)+1)) \n",
    "categories = dict(zip(list(dictCOCOSorted), IdCategories)) \n",
    "\n",
    "# Get the corresponding image ids and images using loadImgs\n",
    "imgIds = coco.getImgIds(catIds=catIds) \n",
    "imgOriginals = coco.loadImgs(imgIds) \n",
    "\n",
    "# The images are selected randomly\n",
    "imgShuffled = sample(imgOriginals, len(imgOriginals))  \n",
    "\n",
    "# Choose the number of images for the training and validation set. default 30-10\n",
    "myImagesTrain, myImagesVal = myImages(imgShuffled, 30, 10)  \n",
    "\n",
    "trainSet = cocoJson(myImagesTrain)\n",
    "createJson(trainSet, train=True)\n",
    "\n",
    "valSet = cocoJson(myImagesVal)\n",
    "createJson(valSet, train=False)\n",
    "\n",
    "Parallel(\n",
    "    n_jobs=-1, prefer=\"threads\")([delayed(downloadImagesToTrain)(img) for img in myImagesTrain])\n",
    "\n",
    "Parallel(\n",
    "    n_jobs=-1, prefer=\"threads\")([delayed(downloadImagesToVal)(img) for img in myImagesVal])\n",
    "\n",
    "print(\"\\nfinish.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d22510",
   "metadata": {},
   "source": [
    "# 2）将minicoco2017数据集转换为mindrecord数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "087a8a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"FasterRcnn dataset\"\"\"\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "\n",
    "import cv2\n",
    "import mindspore as ms\n",
    "import mindspore.dataset as de\n",
    "from mindspore.mindrecord import FileWriter\n",
    "from src.image_process import *\n",
    "\n",
    "\n",
    "def preprocess_fn(image, box, is_training, config):\n",
    "    \"\"\"Preprocess function for dataset.\"\"\"\n",
    "\n",
    "    def _infer_data(image_bgr, image_shape, gt_box_new, gt_label_new, gt_iscrowd_new_revert):\n",
    "        image_shape = image_shape[:2]\n",
    "        input_data = image_bgr, image_shape, gt_box_new, gt_label_new, gt_iscrowd_new_revert\n",
    "\n",
    "        if config.keep_ratio:\n",
    "            input_data = rescale_column_test(*input_data, config=config)\n",
    "        else:\n",
    "            input_data = resize_column_test(*input_data, config=config)\n",
    "        input_data = imnormalize_column(*input_data)\n",
    "\n",
    "        output_data = transpose_column(*input_data)\n",
    "        return output_data\n",
    "\n",
    "    def _data_aug(image, box, is_training):\n",
    "        \"\"\"Data augmentation function.\"\"\"\n",
    "        pad_max_number = config.num_gts\n",
    "        if pad_max_number < box.shape[0]:\n",
    "            box = box[:pad_max_number, :]\n",
    "        image_bgr = image.copy()\n",
    "        image_bgr[:, :, 0] = image[:, :, 2]\n",
    "        image_bgr[:, :, 1] = image[:, :, 1]\n",
    "        image_bgr[:, :, 2] = image[:, :, 0]\n",
    "        image_shape = image_bgr.shape[:2]\n",
    "        gt_box = box[:, :4]\n",
    "        gt_label = box[:, 4]\n",
    "        gt_iscrowd = box[:, 5]\n",
    "\n",
    "        gt_box_new = np.pad(gt_box, ((0, pad_max_number - box.shape[0]), (0, 0)), mode=\"constant\", constant_values=0)\n",
    "        gt_label_new = np.pad(gt_label, ((0, pad_max_number - box.shape[0])), mode=\"constant\", constant_values=-1)\n",
    "        gt_iscrowd_new = np.pad(gt_iscrowd, ((0, pad_max_number - box.shape[0])), mode=\"constant\", constant_values=1)\n",
    "        gt_iscrowd_new_revert = (~(gt_iscrowd_new.astype(np.bool))).astype(np.int32)\n",
    "\n",
    "        if not is_training:\n",
    "            return _infer_data(image_bgr, image_shape, gt_box_new, gt_label_new, gt_iscrowd_new_revert)\n",
    "\n",
    "        flip = (np.random.rand() < config.flip_ratio)\n",
    "        expand = (np.random.rand() < config.expand_ratio)\n",
    "        input_data = image_bgr, image_shape, gt_box_new, gt_label_new, gt_iscrowd_new_revert\n",
    "\n",
    "        if expand:\n",
    "            input_data = expand_column(*input_data)\n",
    "        if config.keep_ratio:\n",
    "            input_data = rescale_column(*input_data, config=config)\n",
    "        else:\n",
    "            input_data = resize_column(*input_data, config=config)\n",
    "        input_data = imnormalize_column(*input_data)\n",
    "        if flip:\n",
    "            input_data = flip_column(*input_data)\n",
    "\n",
    "        output_data = transpose_column(*input_data)\n",
    "        return output_data\n",
    "\n",
    "    return _data_aug(image, box, is_training)\n",
    "\n",
    "\n",
    "def create_coco_label(is_training, config):\n",
    "    \"\"\"Get image path and annotation from COCO.\"\"\"\n",
    "    from pycocotools.coco import COCO\n",
    "\n",
    "    coco_root = config.coco_root  # coco_root: \"./minicoco2017\"\n",
    "    data_type = config.val_data_type\n",
    "    if is_training:\n",
    "        data_type = config.train_data_type  # train_data_type: \"train2017\"\n",
    "\n",
    "    # Classes need to train or test.\n",
    "    train_cls = config.coco_classes  # coco_classes: ['person','car', 'airplane']\n",
    "    train_cls_dict = {}\n",
    "    for i, cls in enumerate(train_cls):\n",
    "        train_cls_dict[cls] = i  # train_cls_dict: {'person': 0, 'airplane': 1, 'car': 2}\n",
    "\n",
    "    anno_json = os.path.join('.', coco_root, config.instance_set.format(data_type))  # anno_json: \"../minicoco2017/annotations/train2017.json\"\n",
    "    if hasattr(config, 'train_set') and is_training:\n",
    "        anno_json = os.path.join(coco_root, config.train_set)\n",
    "    if hasattr(config, 'val_set') and not is_training:\n",
    "        anno_json = os.path.join(coco_root, config.val_set)\n",
    "\n",
    "    # 根据annotations json文件创建COCO类\n",
    "    coco = COCO(anno_json)\n",
    "    classs_dict = {}\n",
    "    cat_ids = coco.loadCats(coco.getCatIds()) # 获取所有的类别信息，loadCats()需要传入 需加载的类别id序列\n",
    "    for cat in cat_ids:\n",
    "        classs_dict[cat[\"id\"]] = cat[\"name\"] # classes_dict: {1:'person', 2:'car'...}\n",
    "\n",
    "    image_ids = coco.getImgIds() # 获取所有 标记所对应的原图id  image_ids: [391895, 522418...]\n",
    "    # 创建要返回的变量\n",
    "    image_files = []\n",
    "    image_anno_dict = {}\n",
    "\n",
    "    for img_id in image_ids:\n",
    "        image_info = coco.loadImgs(img_id)\n",
    "        file_name = image_info[0][\"file_name\"]\n",
    "        anno_ids = coco.getAnnIds(imgIds=img_id, iscrowd=None)\n",
    "        anno = coco.loadAnns(anno_ids)\n",
    "        image_path = os.path.join(coco_root, data_type, file_name)\n",
    "        annos = []\n",
    "        for label in anno:\n",
    "            bbox = label[\"bbox\"]\n",
    "            class_name = classs_dict[label[\"category_id\"]]\n",
    "            if class_name in train_cls:\n",
    "                x1, x2 = bbox[0], bbox[0] + bbox[2]\n",
    "                y1, y2 = bbox[1], bbox[1] + bbox[3]\n",
    "                annos.append([x1, y1, x2, y2] + [train_cls_dict[class_name]] + [int(label[\"iscrowd\"])])\n",
    "\n",
    "        image_files.append(image_path)\n",
    "        if annos:\n",
    "            image_anno_dict[image_path] = np.array(annos)\n",
    "        else:\n",
    "            image_anno_dict[image_path] = np.array([0, 0, 0, 0, 0, 1])\n",
    "\n",
    "    return image_files, image_anno_dict\n",
    "\n",
    "# 可能用于评估\n",
    "def parse_json_annos_from_txt(anno_file, config):\n",
    "    \"\"\"for user defined annotations text file, parse it to json format data\"\"\"\n",
    "    if not os.path.isfile(anno_file):\n",
    "        raise RuntimeError(\"Evaluation annotation file {} is not valid.\".format(anno_file))\n",
    "\n",
    "    annos = {\n",
    "        \"images\": [],\n",
    "        \"annotations\": [],\n",
    "        \"categories\": []\n",
    "    }\n",
    "\n",
    "    # set categories field\n",
    "    for i, cls_name in enumerate(config.coco_classes):\n",
    "        annos[\"categories\"].append({\"id\": i, \"name\": cls_name})\n",
    "\n",
    "    with open(anno_file, \"rb\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    img_id = 1\n",
    "    anno_id = 1\n",
    "    for line in lines:\n",
    "        line_str = line.decode(\"utf-8\").strip()\n",
    "        line_split = str(line_str).split(' ')\n",
    "        # set image field\n",
    "        file_name = line_split[0]\n",
    "        annos[\"images\"].append({\"file_name\": file_name, \"id\": img_id})\n",
    "        # set annotations field\n",
    "        for anno_info in line_split[1:]:\n",
    "            anno = anno_info.split(\",\")\n",
    "            x = float(anno[0])\n",
    "            y = float(anno[1])\n",
    "            w = float(anno[2]) - float(anno[0])\n",
    "            h = float(anno[3]) - float(anno[1])\n",
    "            category_id = int(anno[4])\n",
    "            iscrowd = int(anno[5])\n",
    "            annos[\"annotations\"].append({\"bbox\": [x, y, w, h],\n",
    "                                         \"area\": w * h,\n",
    "                                         \"category_id\": category_id,\n",
    "                                         \"iscrowd\": iscrowd,\n",
    "                                         \"image_id\": img_id,\n",
    "                                         \"id\": anno_id})\n",
    "            anno_id += 1\n",
    "        img_id += 1\n",
    "\n",
    "    return annos\n",
    "\n",
    "\n",
    "def create_train_data_from_txt(image_dir, anno_path):\n",
    "    \"\"\"Filter valid image file, which both in image_dir and anno_path.\"\"\"\n",
    "\n",
    "    def anno_parser(annos_str):\n",
    "        \"\"\"Parse annotation from string to list.\"\"\"\n",
    "        annos = []\n",
    "        for anno_str in annos_str:\n",
    "            anno = anno_str.strip().split(\",\")\n",
    "            xmin, ymin, xmax, ymax = list(map(float, anno[:4]))\n",
    "            cls_id = int(anno[4])\n",
    "            iscrowd = int(anno[5])\n",
    "            annos.append([xmin, ymin, xmax, ymax, cls_id, iscrowd])\n",
    "        return annos\n",
    "\n",
    "    image_files = []\n",
    "    image_anno_dict = {}\n",
    "    if not os.path.isdir(image_dir):\n",
    "        raise RuntimeError(\"Path given is not valid.\")\n",
    "    if not os.path.isfile(anno_path):\n",
    "        raise RuntimeError(\"Annotation file is not valid.\")\n",
    "\n",
    "    with open(anno_path, \"rb\") as f:\n",
    "        lines = f.readlines()\n",
    "    for line in lines:\n",
    "        line_str = line.decode(\"utf-8\").strip()\n",
    "        line_split = str(line_str).split(' ')\n",
    "        file_name = line_split[0]\n",
    "        image_path = os.path.join(image_dir, file_name)\n",
    "        if os.path.isfile(image_path):\n",
    "            image_anno_dict[image_path] = anno_parser(line_split[1:])\n",
    "            image_files.append(image_path)\n",
    "    return image_files, image_anno_dict\n",
    "\n",
    "\n",
    "def data_to_mindrecord_byte_image(config, dataset=\"coco\", is_training=True, prefix=\"fasterrcnn.mindrecord\", file_num=1):\n",
    "    \"\"\"Create MindRecord file.\"\"\"\n",
    "    mindrecord_dir = config.mindrecord_dir  # mindrecord_dir: \"./MindRecord_COCO_TRAIN\"\n",
    "    mindrecord_path = os.path.join(mindrecord_dir, prefix)  # mindrecord_file: \"/MindRecord_COCO_TRAIN/FasterRcnn.mindrecord0\"\n",
    "    writer = FileWriter(mindrecord_path, file_num)\n",
    "    if dataset == \"coco\":\n",
    "        image_files, image_anno_dict = create_coco_label(is_training, config=config)\n",
    "    else:\n",
    "        image_files, image_anno_dict = create_train_data_from_txt(config.image_dir, config.anno_path)\n",
    "\n",
    "    fasterrcnn_json = {\n",
    "        \"image\": {\"type\": \"bytes\"},\n",
    "        \"annotation\": {\"type\": \"int32\", \"shape\": [-1, 6]},\n",
    "    }\n",
    "    writer.add_schema(fasterrcnn_json, \"fasterrcnn_json\")\n",
    "\n",
    "    for image_name in image_files:\n",
    "        with open(image_name, 'rb') as f:\n",
    "            img = f.read()\n",
    "        annos = np.array(image_anno_dict[image_name], dtype=np.int32)\n",
    "        row = {\"image\": img, \"annotation\": annos}\n",
    "        writer.write_raw_data([row])\n",
    "    writer.commit()\n",
    "\n",
    "\n",
    "def create_fasterrcnn_dataset(config, mindrecord_file, batch_size=2, device_num=1, rank_id=0, is_training=True,\n",
    "                              num_parallel_workers=8, python_multiprocessing=False):\n",
    "    \"\"\"Create FasterRcnn dataset with MindDataset.\"\"\"\n",
    "    cv2.setNumThreads(0)\n",
    "    de.config.set_prefetch_size(1)\n",
    "    ds = de.MindDataset(mindrecord_file, columns_list=[\"image\", \"annotation\"], num_shards=device_num, shard_id=rank_id,\n",
    "                        num_parallel_workers=4, shuffle=is_training)\n",
    "    decode = ms.dataset.vision.Decode()\n",
    "    ds = ds.map(input_columns=[\"image\"], operations=decode)\n",
    "    compose_map_func = (lambda image, annotation: preprocess_fn(image, annotation, is_training, config=config))\n",
    "\n",
    "    if is_training:\n",
    "        ds = ds.map(input_columns=[\"image\", \"annotation\"],\n",
    "                    output_columns=[\"image\", \"image_shape\", \"box\", \"label\", \"valid_num\"],\n",
    "                    column_order=[\"image\", \"image_shape\", \"box\", \"label\", \"valid_num\"],\n",
    "                    operations=compose_map_func, python_multiprocessing=python_multiprocessing,\n",
    "                    num_parallel_workers=num_parallel_workers)\n",
    "        ds = ds.batch(batch_size, drop_remainder=True)\n",
    "    else:\n",
    "        ds = ds.map(input_columns=[\"image\", \"annotation\"],\n",
    "                    output_columns=[\"image\", \"image_shape\", \"box\", \"label\", \"valid_num\"],\n",
    "                    column_order=[\"image\", \"image_shape\", \"box\", \"label\", \"valid_num\"],\n",
    "                    operations=compose_map_func,\n",
    "                    num_parallel_workers=num_parallel_workers)\n",
    "        ds = ds.batch(batch_size, drop_remainder=True)\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcad9864",
   "metadata": {},
   "source": [
    "# 生成anchor\n",
    "在Faster-RCNN网络的RPN阶段中，需要根据backbone网络抽取的feature map的大小，对每个点生成相应的anchor。所谓anchor，实际上就是一组矩形框，它们的大小、尺寸、位置坐标由base_size、scales、ratios和featmap_size决定。对于一个由ResNet50提取的特征图feature map，生成anchor的大致流程如下：\n",
    "1) 首先有个base_size，指定生成的基础anchor的大小，生成的基础anchor的长和宽都是base_size，这时候只有一个anchor；\n",
    "\n",
    "2) 以base_size的大小为基础，按照三种长宽比ratios{2:1, 1:1, 1:2}，生成指定长宽比的基础anchor；\n",
    "\n",
    "3) 根据指定的缩放比例，对基础anchor进行缩放，本案例中缩放比例一共有1种，缩放比例为8，三种长宽比和一种缩放比例，就得到了3 * 1 = 3个基础anchor；\n",
    "\n",
    "4) 上面的过程描述了特征上一个cell对应的anchor的生成过程，对于特征图上的每个cell，都要生成3个anchor。在本案例中，提供了一个stride参数，用于将在feature map上生成的anchor尺寸还原为原图中的anchor尺寸。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a59ceb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class AnchorGenerator():\n",
    "    def __init__(self, base_size, scales, ratios):\n",
    "        self.base_size = base_size\n",
    "        self.scales = np.array(scales)\n",
    "        self.ratios = np.array(ratios)\n",
    "        self.base_anchors = self.gen_base_anchors()\n",
    "    def gen_base_anchors(self):\n",
    "        # 生成feather map中一个点的anchors\n",
    "        w = self.base_size\n",
    "        h = self.base_size\n",
    "        x_ctr = 0.5 * (w - 1)\n",
    "        y_ctr = 0.5 * (h - 1)\n",
    "        h_ratios = np.sqrt(self.ratios)\n",
    "        w_ratios = 1 / h_ratios\n",
    "        ws = (w * w_ratios[:, None] * self.scales[None, :]).reshape(-1)\n",
    "        hs = (h * h_ratios[:, None] * self.scales[None, :]).reshape(-1)\n",
    "        base_anchors = np.stack([\n",
    "            x_ctr - 0.5 * (ws - 1), y_ctr - 0.5 * (hs - 1),\n",
    "            x_ctr + 0.5 * (ws - 1), y_ctr + 0.5 * (hs - 1)\n",
    "        ], axis=-1).round()\n",
    "        return base_anchors\n",
    "    def _meshgrid(self, x, y, row_major=True):\n",
    "        xx = np.repeat(x.reshape(1, len(x)), len(y), axis=0).reshape(-1)\n",
    "        yy = np.repeat(y, len(x))\n",
    "        if row_major:\n",
    "            return xx, yy\n",
    "        return yy, xx\n",
    "    def grid_anchors(self, featmap_size, stride=16):\n",
    "        # 根据feature map的大小，生成对应的所有anchors\n",
    "        base_anchors = self.base_anchors\n",
    "        \n",
    "        feat_h, feat_w = featmap_size\n",
    "        shift_x = np.arange(0, feat_w) * stride\n",
    "        shift_y = np.arange(0, feat_h) * stride\n",
    "        shift_xx, shift_yy = self._meshgrid(shift_x, shift_y)\n",
    "        shifts = np.stack([shift_xx, shift_yy, shift_xx, shift_yy], axis=-1)\n",
    "        shifts = shifts.astype(base_anchors.dtype)\n",
    "        all_anchors = base_anchors[None, :, :] + shifts[:, None, :]\n",
    "        all_anchors = all_anchors.reshape(-1, 4)\n",
    "        \n",
    "        return all_anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99e7b7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 192*320 feature map, the number of generated anchors is 184320.\n",
      "Generated anchors as follow:\n",
      "[[ -21.   -9.   24.   12.]\n",
      " [ -14.  -14.   17.   17.]\n",
      " [  -9.  -21.   12.   24.]\n",
      " ...\n",
      " [1255.  755. 1300.  776.]\n",
      " [1262.  750. 1293.  781.]\n",
      " [1267.  743. 1288.  788.]]\n"
     ]
    }
   ],
   "source": [
    "base_size = 4\n",
    "scales = [8]\n",
    "ratios = [0.5, 1.0, 2.0]\n",
    "featmap_size = [192, 320]\n",
    "stride = 4\n",
    "x = AnchorGenerator(base_size, scales, ratios)\n",
    "all_anchors = x.grid_anchors(featmap_size, stride)\n",
    "print(f\"For {featmap_size[0]}*{featmap_size[1]} feature map, the number of generated anchors is {len(all_anchors)}.\")\n",
    "print(f\"Generated anchors as follow:\")\n",
    "print(all_anchors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15f8257",
   "metadata": {},
   "source": [
    "# ResNet50 backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78b609a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mindspore.nn as nn\n",
    "from mindspore.common.tensor import Tensor\n",
    "import mindspore.ops as ops\n",
    "import mindspore as ms\n",
    "\n",
    "def _conv(in_channels, out_channels, kernel_size=3, stride=1, padding=0, pad_mode='pad'):\n",
    "    shape = (out_channels, in_channels, kernel_size, kernel_size)\n",
    "    weights = Tensor(np.full(shape, 0.01).astype(np.float32))\n",
    "    return nn.Conv2d(in_channels, out_channels,\n",
    "                    kernel_size=kernel_size, stride=stride, padding=padding,\n",
    "                    pad_mode=pad_mode, weight_init=weights, has_bias=False)\n",
    "def _BatchNorm2dInit(out_chls, momentum=0.1, affine=True, use_batch_statistics=True):\n",
    "    dtype = np.float32\n",
    "    gamma_init = Tensor(np.array(np.ones(out_chls)).astype(dtype))\n",
    "    beta_init = Tensor(np.array(np.ones(out_chls) * 0).astype(dtype))\n",
    "    moving_mean_init = Tensor(np.array(np.ones(out_chls) * 0).astype(dtype))\n",
    "    moving_var_init = Tensor(np.array(np.ones(out_chls)).astype(dtype))\n",
    "    return nn.BatchNorm2d(out_chls, momentum=momentum, affine=affine, gamma_init=gamma_init,\n",
    "                          beta_init=beta_init, moving_mean_init=moving_mean_init,\n",
    "                          moving_var_init=moving_var_init, use_batch_statistics=use_batch_statistics)\n",
    "class ResNetFea(nn.Cell):\n",
    "    def __init__(self, block, layer_nums, in_channels, out_channels, weights_update=False):\n",
    "        super(ResNetFea, self).__init__()\n",
    "        bn_training = False  # 训练时是否更新某一层的权重\n",
    "        self.conv1 = _conv(3, 64, kernel_size=7, stride=2, padding=3, pad_mode='pad')\n",
    "        self.bn1 = _BatchNorm2dInit(64, affine=bn_training, use_batch_statistics=bn_training)\n",
    "        self.relu = ops.ReLU()\n",
    "        self.maxpool = ops.MaxPool(kernel_size=3, strides=2, pad_mode=\"SAME\")\n",
    "        self.weights_update = weights_update\n",
    "        \n",
    "        if not self.weights_update:\n",
    "            self.conv1.weight.requires_grad = False\n",
    "        \n",
    "        self.layer1 = self._make_layer(block, \n",
    "                                       layer_nums[0], \n",
    "                                       in_channel=in_channels[0], \n",
    "                                       out_channel=out_channels[0], \n",
    "                                       stride=1, \n",
    "                                       training=bn_training, \n",
    "                                       weights_update=self.weights_update)\n",
    "        self.layer2 = self._make_layer(block, \n",
    "                                       layer_nums[1], \n",
    "                                       in_channel=in_channels[1], \n",
    "                                       out_channel=out_channels[1], \n",
    "                                       stride=2, \n",
    "                                       training=bn_training, \n",
    "                                       weights_update=True)\n",
    "        self.layer3 = self._make_layer(block, \n",
    "                                       layer_nums[2], \n",
    "                                       in_channel=in_channels[2], \n",
    "                                       out_channel=out_channels[2], \n",
    "                                       stride=2, \n",
    "                                       training=bn_training, \n",
    "                                       weights_update=True)\n",
    "        self.layer4 = self._make_layer(block, \n",
    "                                       layer_nums[3], \n",
    "                                       in_channel=in_channels[3], \n",
    "                                       out_channel=out_channels[3], \n",
    "                                       stride=2, \n",
    "                                       training=bn_training, \n",
    "                                       weights_update=True)\n",
    "    def _make_layer(self, block, layer_num, in_channel, out_channel, stride, training=False, weights_update=False):\n",
    "        layers = []\n",
    "        down_sample = False\n",
    "        if stride != 1 or in_channel != out_channel:\n",
    "            down_sample = True\n",
    "        resblk = block(in_channel, out_channel, stride=stride, down_sample=down_sample, training=training, weights_update=weights_update)\n",
    "        layers.append(resblk)\n",
    "        \n",
    "        for _ in range(1, layer_num):\n",
    "            resblk = block(out_channel, out_channel, stride=1, training=training, weights_update=weights_update)\n",
    "            layers.append(resblk)\n",
    "        \n",
    "        return nn.SequentialCell(layers)\n",
    "    def construct(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        c1 = self.maxpool(x)\n",
    "        \n",
    "        c2 = self.layer1(c1)\n",
    "        identity = c2\n",
    "        if not self.weights_update:\n",
    "            identity = ops.stop_gradient(c2)\n",
    "        c3 = self.layer2(identity)\n",
    "        c4 = self.layer3(c3)\n",
    "        c5 = self.layer4(c4)\n",
    "\n",
    "        return identity, c3, c4, c5\n",
    "class ResidualBlock(nn.Cell):\n",
    "    expansion = 4\n",
    "    def __init__(self, in_channels, out_channels,stride=1,down_sample=False,momentum=0.1,training=False, weights_update=False):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.affine = weights_update\n",
    "        \n",
    "        out_chls = out_channels // self.expansion\n",
    "        self.conv1 = _conv(in_channels, out_chls, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn1 = _BatchNorm2dInit(out_chls, momentum=momentum, affine=self.affine, use_batch_statistics=training)\n",
    "        self.conv2 = _conv(out_chls, out_chls, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn2 = _BatchNorm2dInit(out_chls, momentum=momentum, affine=self.affine, use_batch_statistics=training)\n",
    "        self.conv3 = _conv(out_chls, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn3 = _BatchNorm2dInit(out_channels, momentum=momentum, affine=self.affine, use_batch_statistics=training)\n",
    "        \n",
    "        if training:\n",
    "            self.bn1 = self.bn1.set_train()\n",
    "            self.bn2 = self.bn2.set_train()\n",
    "            self.bn3 = self.bn3.set_train()\n",
    "        \n",
    "        if not weights_update:\n",
    "            self.conv1.weight.requires_grad = False\n",
    "            self.conv2.weight.requires_grad = False\n",
    "            self.conv3.weight.requires_grad = False\n",
    "        \n",
    "        self.relu = ops.ReLU()\n",
    "        self.downsample = down_sample\n",
    "        if self.downsample:\n",
    "            self.conv_down_sample = _conv(in_channels, out_channels, kernel_size=1, stride=stride, padding=0)\n",
    "            self.bn_down_sample = _BatchNorm2dInit(out_channels, momentum=momentum, affine=self.affine,\n",
    "                                                   use_batch_statistics=training)\n",
    "            if training:\n",
    "                self.bn_down_sample = self.bn_down_sample.set_train()\n",
    "            if not weights_update:\n",
    "                self.conv_down_sample.weight.requires_grad = False\n",
    "        self.add = ops.Add()\n",
    "    def construct(self, x):\n",
    "        identity = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        \n",
    "        if self.downsample:\n",
    "            identity = self.conv_down_sample(identity)\n",
    "            identity = self.bn_down_sample(identity)\n",
    "        \n",
    "        out = self.add(out, identity)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "349ec01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 256, 56, 56)\n",
      "(1, 512, 28, 28)\n",
      "(1, 1024, 14, 14)\n",
      "(1, 2048, 7, 7)\n"
     ]
    }
   ],
   "source": [
    "resnet = ResNetFea(ResidualBlock, [3, 4, 6, 3],[64, 256, 512, 1024],[256, 512, 1024, 2048],False)\n",
    "x = Tensor(np.random.rand(1, 3, 224, 224), ms.float32)\n",
    "x = resnet(x)\n",
    "for i in range(len(x)):\n",
    "    print(x[i].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af0282b",
   "metadata": {},
   "source": [
    "# Faster-RCNN主干网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5abd8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore.nn as nn\n",
    "import numpy as np\n",
    "class Faster_Rcnn(nn.Cell):\n",
    "    def __init__(self):\n",
    "        self.dtype = np.float32\n",
    "        self.ms_type = ms.float32\n",
    "        self.train_batch_size = 2  # 设置训练时的batch大小为2\n",
    "        self.without_bg_loss = True  # ?\n",
    "        self.num_classes = 4  # 设置预测类别的个数，算上了背景类别\n",
    "        self.num_cls_bbox = 3  # 设置类别框的个数，不预测背景的框\n",
    "        self.anchor_scales = [8]  # anchor尺寸\n",
    "        self.anchor_ratios = [0.5, 1.0, 2.0]  # anchor长宽比\n",
    "        self.anchor_strides = [4, 8, 16, 32, 64] # ?\n",
    "        self.target_means = tuple([0., 0., 0., 0.]) # ?\n",
    "        self.target_stds = tuple([0.1, 0.1, 0.2, 0.2]) # ?\n",
    "        \n",
    "        # 创建anchor生成器\n",
    "        self.anchor_base_sizes = list(self.anchor_strides)\n",
    "        self.anchor_generators = []\n",
    "        for anchor_base in self.anchor_base_sizes:\n",
    "            self.anchor_generators.append(AnchorGenerator(anchor_base, self.anchor_scales, self.anchor_ratios))\n",
    "        self.num_anchors = len(self.anchor_ratios) * len(self.anchor_scales)\n",
    "        featmap_sizes = [[192, 320], [96, 160], [48, 80], [24, 40], [12, 20]]\n",
    "        assert len(featmap_sizes) == len(self.anchor_generators)\n",
    "        self.anchor_list = self.get_anchors(featmap_sizes)\n",
    "        \n",
    "        # ResNet backbone\n",
    "        self.backbone = ResNetFea(ResidualBlock, [3,4,6,3], [64,256,512,1024], [256,512,1024,2048])\n",
    "    def construct(self,):\n",
    "        pass\n",
    "    \n",
    "    def get_anchors(self, featmap_sizes):\n",
    "        num_levels = len(featmap_sizes)\n",
    "        multi_level_anchors = ()\n",
    "        for i in range(num_levels):\n",
    "            anchors = self.anchor_generators[i].grid_anchors(featmap_sizes[i], self.anchor_strides[i])\n",
    "            multi_level_anchors += (Tensor(anchors.astype(self.dtype)),)\n",
    "        \n",
    "        return multi_level_anchors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mindspore_py37] *",
   "language": "python",
   "name": "conda-env-mindspore_py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
